---
title: "2016 release"
output: html_document
---

install.packages("curl")
install.packages("dplyr")
install.packages("tidyverse")
install.packages("gplots")
install.packages("corrplot")
install.packages("ggplot2")
install.packages("vegan")
install.packages("data.table")
install.packages("tidyr")
install.packages("formattable")
install.packages("survival")
install.packages("igraph")
install.packages("ggraph")

```{r}
library(curl)
library(dplyr)
library(tidyverse)
library(gplots)
library(corrplot)
library(ggplot2)
library(vegan)
library(data.table)
library(tidyr)
library(formattable)
library(survival)
library(igraph)
library(ggraph)
```

## Importing the pre-focals datasheet
```{r}
pre_focals<- curl("https://raw.githubusercontent.com/langley1/LWTdata2016/main/2016_pre-release_FOCALS.csv")
pre_focals<- read.csv(pre_focals, header = T)
head(pre_focals)
nrow(pre_focals)
summary(pre_focals)
names(pre_focals)
unique(pre_focals$FOCAL.ID)
n_distinct(pre_focals$FOCAL.ID)
unique(pre_focals$AGE)
sort(table(pre_focals$BEHAVIOUR), decreasing = TRUE)
n_distinct(pre_focals$FOCAL.REFERENCE.CODE) #1012 total focals
```

## Creating an Age/Sex plot
```{r}
age_sex_plot <- ggplot(pre_focals, aes(SEX, group = AGE)) + 
          geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") + 
          scale_y_continuous(labels=scales::percent) +
          ylab("relative frequencies") +
          facet_grid(~AGE)
age_sex_plot #There are more female than male adults, almost all subadults are males, and more juveniles are females... overall more females than males 
```

## POPs
## Filtering out Pops from the pre-focals dataset
```{r}
Pops<- pre_focals %>% filter(FOCAL.ID == "PO")
head(Pops)
n_distinct(Pops$FOCAL.REFERENCE.CODE) #56 distinct focals
unique(Pops$FOCAL.REFERENCE.CODE)
```

### Testing to see if I get the same SD value if I 1) do three focals separately and then find the average SD and 2)combine all three focals into one df and then find the SD for that 
```{r}
#These three chunks are each focal separately
Pops_behaviorcount<- Pops %>% 
  filter(FOCAL.REFERENCE.CODE == "10101") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Pops_behaviorcount

Pops_behaviorcount2<- Pops %>% 
  filter(FOCAL.REFERENCE.CODE == "10407") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Pops_behaviorcount2

Pops_behaviorcount3<- Pops %>% 
  filter(FOCAL.REFERENCE.CODE == "20109") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Pops_behaviorcount3

#Finding SD for each focal
SD1<- diversity(Pops_behaviorcount$count)
SD2<- diversity(Pops_behaviorcount2$count)
SD3<- diversity(Pops_behaviorcount3$count)

SD1
SD2
SD3
SDs<- c(SD1,SD2,SD3) #combining the focals
AvgSD<- mean(SDs)
AvgSD #1.145476

#Now I'm filtering out all 3 focals so that it counts the behaviors across all three
Pops_behaviorcount4<- Pops %>% 
  filter(FOCAL.REFERENCE.CODE %in% c("10101","10407","20109")) %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Pops_behaviorcount4

#finding the SD for this one df
SD4<- diversity(Pops_behaviorcount4$count)
SD4 #1.307044

#The SD values are DIFFERENT for the two methods! 
```

### Getting one SD value for all of Pops 56 focals... I don't think this is a reliable value?
```{r}
Pops_behaviorcountTEST2<- Pops %>% 
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Pops_behaviorcountTEST2

DIVTEST<- diversity(Pops_behaviorcountTEST2$count)
DIVTEST #1.459
```

### Playing around with the two behavior columns for one of Pop's focals, I need to somehow incorporate the behaviors from the Behavior.2 column into my SD calculations (don't know how to do this yet)
```{r}
Pops_behaviorcount2<- Pops %>% 
  filter(FOCAL.REFERENCE.CODE == "10407") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Pops_behaviorcount2

Pops_behaviorcount3<- Pops %>% 
  filter(FOCAL.REFERENCE.CODE == "10407") %>%
  group_by(BEHAVIOUR.2) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Pops_behaviorcount3
```

### Practicing running SD calculations by "hand" first
```{r}
sum(Pops_behaviorcount$count) #20
pI <- Pops_behaviorcount$count/sum(Pops_behaviorcount$count)
pI
H.I <- -sum(pI*log(pI))
H.I #0.7999
test<- diversity(Pops_behaviorcount$count)
test #0.7999, they match
```

### Since I can't find SD for each of the 56 focals (don't know how to do it at least), I'm going to find a SD for each month during pre-release observations
```{r}
#Month 6
Pops_behaviorcount_month6<- Pops %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Pops_behaviorcount_month6

Pop_month6_SD<- diversity(Pops_behaviorcount_month6$count)
Pop_month6_SD

#Month 7
Pops_behaviorcount_month7<- Pops %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Pops_behaviorcount_month7

Pop_month7_SD<- diversity(Pops_behaviorcount_month7$count)
Pop_month7_SD

#Month 8
Pops_behaviorcount_month8<- Pops %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Pops_behaviorcount_month8

Pop_month8_SD<- diversity(Pops_behaviorcount_month8$count)
Pop_month8_SD

#Month 9
Pops_behaviorcount_month9<- Pops %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Pops_behaviorcount_month9

Pop_month9_SD<- diversity(Pops_behaviorcount_month9$count)
Pop_month9_SD
```

### Averaging the SDs across Pop's 4 months pre-release
```{r}
Pops_pre_allSDs<- c(Pop_month6_SD,Pop_month7_SD,Pop_month8_SD,Pop_month9_SD)
Pops_pre_allSDs
Pop_pre_avgSDs<- mean(Pops_pre_allSDs)
Pop_pre_avgSDs #1.377789
```

## ZIP
## Filtering out Zip from the pre-focals dataset
```{r}
Zip<- pre_focals %>% filter(FOCAL.ID == "ZI")
n_distinct(Zip$FOCAL.REFERENCE.CODE) #56 distinct focals
```

### Getting SD for each month for Zip during pre-release observations
```{r}
#Month 6
Zip_behaviorcount_month6<- Zip %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Zip_behaviorcount_month6

Zip_month6_SD<- diversity(Zip_behaviorcount_month6$count)
Zip_month6_SD

#Month 7
Zip_behaviorcount_month7<- Zip %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Zip_behaviorcount_month7

Zip_month7_SD<- diversity(Zip_behaviorcount_month7$count)
Zip_month7_SD

#Month 8
Zip_behaviorcount_month8<- Zip %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Zip_behaviorcount_month8

Zip_month8_SD<- diversity(Zip_behaviorcount_month8$count)
Zip_month8_SD

#Month 9
Zip_behaviorcount_month9<- Zip %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Zip_behaviorcount_month9

Zip_month9_SD<- diversity(Zip_behaviorcount_month9$count)
Zip_month9_SD
```

### Averaging the SDs across Zip's 4 months pre-release
```{r}
Zip_pre_allSDs<- c(Zip_month6_SD,Zip_month7_SD,Zip_month8_SD,Zip_month9_SD)
Zip_pre_avgSDs<- mean(Zip_pre_allSDs)
Zip_pre_avgSDs
```

## JACK
## Filtering out Jack from the pre-focals dataset
```{r}
Jack<- pre_focals %>% filter(FOCAL.ID == "JA")
n_distinct(Jack$FOCAL.REFERENCE.CODE) #56 distinct focals
```

### Getting SD for each month for Jack during pre-release observations
```{r}
#Month 6
Jack_behaviorcount_month6<- Jack %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Jack_behaviorcount_month6

Jack_month6_SD<- diversity(Jack_behaviorcount_month6$count)
Jack_month6_SD

#Month 7
Jack_behaviorcount_month7<- Jack %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Jack_behaviorcount_month7

Jack_month7_SD<- diversity(Jack_behaviorcount_month7$count)
Jack_month7_SD

#Month 8
Jack_behaviorcount_month8<- Jack %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Jack_behaviorcount_month8

Jack_month8_SD<- diversity(Jack_behaviorcount_month8$count)
Jack_month8_SD

#Month 9
Jack_behaviorcount_month9<- Jack %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Jack_behaviorcount_month9

Jack_month9_SD<- diversity(Jack_behaviorcount_month9$count)
Jack_month9_SD
```

### Averaging the SDs across Jack's 4 months pre-release
```{r}
Jack_pre_allSDs<- c(Jack_month6_SD,Jack_month7_SD,Jack_month8_SD,Jack_month9_SD)
Jack_pre_avgSDs<- mean(Jack_pre_allSDs)
Jack_pre_avgSDs
```

## BLUE
## Filtering out Blue from the pre-focals dataset
```{r}
Blue<- pre_focals %>% filter(FOCAL.ID == "BL")
n_distinct(Blue$FOCAL.REFERENCE.CODE) #56 distinct focals
```

### Getting SD for each month for Blue during pre-release observations
```{r}
#Month 6
Blue_behaviorcount_month6<- Blue %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Blue_behaviorcount_month6

Blue_month6_SD<- diversity(Blue_behaviorcount_month6$count)
Blue_month6_SD

#Month 7
Blue_behaviorcount_month7<- Blue %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Blue_behaviorcount_month7

Blue_month7_SD<- diversity(Blue_behaviorcount_month7$count)
Blue_month7_SD

#Month 8
Blue_behaviorcount_month8<- Blue %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Blue_behaviorcount_month8

Blue_month8_SD<- diversity(Blue_behaviorcount_month8$count)
Blue_month8_SD

#Month 9
Blue_behaviorcount_month9<- Blue %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Blue_behaviorcount_month9

Blue_month9_SD<- diversity(Blue_behaviorcount_month9$count)
Blue_month9_SD
```

### Averaging the SDs across Blue's 4 months pre-release
```{r}
Blue_pre_allSDs<- c(Blue_month6_SD,Blue_month7_SD,Blue_month8_SD,Blue_month9_SD)
Blue_pre_avgSDs<- mean(Blue_pre_allSDs)
Blue_pre_avgSDs
```

## ALEX
## Filtering out Alex from the pre-focals dataset
```{r}
Alex<- pre_focals %>% filter(FOCAL.ID == "AL")
n_distinct(Alex$FOCAL.REFERENCE.CODE) #56 distinct focals
```

### Getting SD for each month for Alex during pre-release observations
```{r}
#Month 6
Alex_behaviorcount_month6<- Alex %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Alex_behaviorcount_month6

Alex_month6_SD<- diversity(Alex_behaviorcount_month6$count)
Alex_month6_SD

#Month 7
Alex_behaviorcount_month7<- Alex %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Alex_behaviorcount_month7

Alex_month7_SD<- diversity(Alex_behaviorcount_month7$count)
Alex_month7_SD

#Month 8
Alex_behaviorcount_month8<- Alex %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Alex_behaviorcount_month8

Alex_month8_SD<- diversity(Alex_behaviorcount_month8$count)
Alex_month8_SD

#Month 9
Alex_behaviorcount_month9<- Alex %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Alex_behaviorcount_month9

Alex_month9_SD<- diversity(Alex_behaviorcount_month9$count)
Alex_month9_SD
```

### Averaging the SDs across Alex's 4 months pre-release
```{r}
Alex_pre_allSDs<- c(Alex_month6_SD,Alex_month7_SD,Alex_month8_SD,Alex_month9_SD)
Alex_pre_avgSDs<- mean(Alex_pre_allSDs)
Alex_pre_avgSDs
```

## BART
## Filtering out Bart from the pre-focals dataset
```{r}
Bart<- pre_focals %>% filter(FOCAL.ID == "BA")
n_distinct(Bart$FOCAL.REFERENCE.CODE) #56 distinct focals
```

### Getting SD for each month for Bart during pre-release observations
```{r}
#Month 6
Bart_behaviorcount_month6<- Bart %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Bart_behaviorcount_month6

Bart_month6_SD<- diversity(Bart_behaviorcount_month6$count)
Bart_month6_SD

#Month 7
Bart_behaviorcount_month7<- Bart %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Bart_behaviorcount_month7

Bart_month7_SD<- diversity(Bart_behaviorcount_month7$count)
Bart_month7_SD

#Month 8
Bart_behaviorcount_month8<- Bart %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Bart_behaviorcount_month8

Bart_month8_SD<- diversity(Bart_behaviorcount_month8$count)
Bart_month8_SD

#Month 9
Bart_behaviorcount_month9<- Bart %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Bart_behaviorcount_month9

Bart_month9_SD<- diversity(Bart_behaviorcount_month9$count)
Bart_month9_SD
```

## NEVILLE
## Filtering out Nev from the pre-focals dataset
```{r}
Nev<- pre_focals %>% filter(FOCAL.ID == "NE")
n_distinct(Nev$FOCAL.REFERENCE.CODE) #56 distinct focals
```

### Getting SD for each month for Neville during pre-release observations
```{r}
#Month 6
Nev_behaviorcount_month6<- Nev %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Nev_behaviorcount_month6

Nev_month6_SD<- diversity(Nev_behaviorcount_month6$count)
Nev_month6_SD

#Month 7
Nev_behaviorcount_month7<- Nev %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Nev_behaviorcount_month7

Nev_month7_SD<- diversity(Nev_behaviorcount_month7$count)
Nev_month7_SD

#Month 8
Nev_behaviorcount_month8<- Nev %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Nev_behaviorcount_month8

Nev_month8_SD<- diversity(Nev_behaviorcount_month8$count)
Nev_month8_SD

#Month 9
Nev_behaviorcount_month9<- Nev %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Nev_behaviorcount_month9

Nev_month9_SD<- diversity(Nev_behaviorcount_month9$count)
Nev_month9_SD
```

### Averaging the SDs across Nev's 4 months pre-release
```{r}
Nev_pre_allSDs<- c(Nev_month6_SD,Nev_month7_SD,Nev_month8_SD,Nev_month9_SD)
Nev_pre_avgSDs<- mean(Nev_pre_allSDs)
Nev_pre_avgSDs
```

## AUGUSTINE
## Filtering out Aug from the pre-focals dataset
```{r}
Aug<- pre_focals %>% filter(FOCAL.ID == "AU")
n_distinct(Aug$FOCAL.REFERENCE.CODE) #58 distinct focals
```

### Getting SD for each month for Aug during pre-release observations
```{r}
#Month 6
Aug_behaviorcount_month6<- Aug %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Aug_behaviorcount_month6

Aug_month6_SD<- diversity(Aug_behaviorcount_month6$count)
Aug_month6_SD

#Month 7
Aug_behaviorcount_month7<- Aug %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Aug_behaviorcount_month7

Aug_month7_SD<- diversity(Aug_behaviorcount_month7$count)
Aug_month7_SD

#Month 8
Aug_behaviorcount_month8<- Aug %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Aug_behaviorcount_month8

Aug_month8_SD<- diversity(Aug_behaviorcount_month8$count)
Aug_month8_SD

#Month 9
Aug_behaviorcount_month9<- Aug %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Aug_behaviorcount_month9

Aug_month9_SD<- diversity(Aug_behaviorcount_month9$count)
Aug_month9_SD
```

### Averaging the SDs across Aug's 4 months pre-release
```{r}
Aug_pre_allSDs<- c(Aug_month6_SD,Aug_month7_SD,Aug_month8_SD,Aug_month9_SD)
Aug_pre_avgSDs<- mean(Aug_pre_allSDs)
Aug_pre_avgSDs
```

## AMY
## Filtering out Amy from the pre-focals dataset
```{r}
Amy<- pre_focals %>% filter(FOCAL.ID == "AM")
n_distinct(Amy$FOCAL.REFERENCE.CODE) #56 distinct focals
```

### Getting SD for each month for Amy during pre-release observations
```{r}
#Month 6
Amy_behaviorcount_month6<- Amy %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Amy_behaviorcount_month6

Amy_month6_SD<- diversity(Amy_behaviorcount_month6$count)
Amy_month6_SD

#Month 7
Amy_behaviorcount_month7<- Amy %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Amy_behaviorcount_month7

Amy_month7_SD<- diversity(Amy_behaviorcount_month7$count)
Amy_month7_SD

#Month 8
Amy_behaviorcount_month8<- Amy %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Amy_behaviorcount_month8

Amy_month8_SD<- diversity(Amy_behaviorcount_month8$count)
Amy_month8_SD

#Month 9
Amy_behaviorcount_month9<- Amy %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Amy_behaviorcount_month9

Amy_month9_SD<- diversity(Amy_behaviorcount_month9$count)
Amy_month9_SD
```

### Averaging the SDs across Amy's 4 months pre-release
```{r}
Amy_pre_allSDs<- c(Amy_month6_SD,Amy_month7_SD,Amy_month8_SD,Amy_month9_SD)
Amy_pre_avgSDs<- mean(Amy_pre_allSDs)
Amy_pre_avgSDs
```

## MAY
## Filtering out May from the pre-focals dataset
```{r}
May<- pre_focals %>% filter(FOCAL.ID == "MA")
n_distinct(May$FOCAL.REFERENCE.CODE) #57 distinct focals
```

### Getting SD for each month for May during pre-release observations
```{r}
#Month 6
May_behaviorcount_month6<- May %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
May_behaviorcount_month6

May_month6_SD<- diversity(May_behaviorcount_month6$count)
May_month6_SD

#Month 7
May_behaviorcount_month7<- May %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
May_behaviorcount_month7

May_month7_SD<- diversity(May_behaviorcount_month7$count)
May_month7_SD

#Month 8
May_behaviorcount_month8<- May %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
May_behaviorcount_month8

May_month8_SD<- diversity(May_behaviorcount_month8$count)
May_month8_SD

#Month 9
May_behaviorcount_month9<- May %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
May_behaviorcount_month9

May_month9_SD<- diversity(May_behaviorcount_month9$count)
May_month9_SD
```

### Averaging the SDs across May's 4 months pre-release
```{r}
May_pre_allSDs<- c(May_month6_SD,May_month7_SD,May_month8_SD,May_month9_SD)
May_pre_avgSDs<- mean(May_pre_allSDs)
May_pre_avgSDs
```

## TONI
## Filtering out Toni from the pre-focals dataset
```{r}
Toni<- pre_focals %>% filter(FOCAL.ID == "TO")
n_distinct(Toni$FOCAL.REFERENCE.CODE) #55 distinct focals
```

### Getting SD for each month for Toni during pre-release observations
```{r}
#Month 6
Toni_behaviorcount_month6<- Toni %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Toni_behaviorcount_month6

Toni_month6_SD<- diversity(Toni_behaviorcount_month6$count)
Toni_month6_SD

#Month 7
Toni_behaviorcount_month7<- Toni %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Toni_behaviorcount_month7

Toni_month7_SD<- diversity(Toni_behaviorcount_month7$count)
Toni_month7_SD

#Month 8
Toni_behaviorcount_month8<- Toni %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Toni_behaviorcount_month8

Toni_month8_SD<- diversity(Toni_behaviorcount_month8$count)
Toni_month8_SD

#Month 9
Toni_behaviorcount_month9<- Toni %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Toni_behaviorcount_month9

Toni_month9_SD<- diversity(Toni_behaviorcount_month9$count)
Toni_month9_SD
```

### Averaging the SDs across Toni's 4 months pre-release
```{r}
Toni_pre_allSDs<- c(Toni_month6_SD,Toni_month7_SD,Toni_month8_SD,Toni_month9_SD)
Toni_pre_avgSDs<- mean(Toni_pre_allSDs)
Toni_pre_avgSDs
```

## BOO
## Filtering out Boo from the pre-focals dataset
```{r}
Boo<- pre_focals %>% filter(FOCAL.ID == "BO")
n_distinct(Boo$FOCAL.REFERENCE.CODE) #55 distinct focals
```

### Getting SD for each month for Boo during pre-release observations
```{r}
#Month 6
Boo_behaviorcount_month6<- Boo %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Boo_behaviorcount_month6

Boo_month6_SD<- diversity(Boo_behaviorcount_month6$count)
Boo_month6_SD

#Month 7
Boo_behaviorcount_month7<- Boo %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Boo_behaviorcount_month7

Boo_month7_SD<- diversity(Boo_behaviorcount_month7$count)
Boo_month7_SD

#Month 8
Boo_behaviorcount_month8<- Boo %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Boo_behaviorcount_month8

Boo_month8_SD<- diversity(Boo_behaviorcount_month8$count)
Boo_month8_SD

#Month 9
Boo_behaviorcount_month9<- Boo %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Boo_behaviorcount_month9

Boo_month9_SD<- diversity(Boo_behaviorcount_month9$count)
Boo_month9_SD
```

### Averaging the SDs across Boo's 4 months pre-release
```{r}
Boo_pre_allSDs<- c(Boo_month6_SD,Boo_month7_SD,Boo_month8_SD,Boo_month9_SD)
Boo_pre_avgSDs<- mean(Boo_pre_allSDs)
Boo_pre_avgSDs
```

## BIG MAMA
## Filtering out Bgm from the pre-focals dataset
```{r}
Bgm<- pre_focals %>% filter(FOCAL.ID == "BM")
n_distinct(Bgm$FOCAL.REFERENCE.CODE) #56 distinct focals
```

### Getting SD for each month for Bgm during pre-release observations
```{r}
#Month 6
Bgm_behaviorcount_month6<- Bgm %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Bgm_behaviorcount_month6

Bgm_month6_SD<- diversity(Bgm_behaviorcount_month6$count)
Bgm_month6_SD

#Month 7
Bgm_behaviorcount_month7<- Bgm %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Bgm_behaviorcount_month7

Bgm_month7_SD<- diversity(Bgm_behaviorcount_month7$count)
Bgm_month7_SD

#Month 8
Bgm_behaviorcount_month8<- Bgm %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Bgm_behaviorcount_month8

Bgm_month8_SD<- diversity(Bgm_behaviorcount_month8$count)
Bgm_month8_SD

#Month 9
Bgm_behaviorcount_month9<- Bgm %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Bgm_behaviorcount_month9

Bgm_month9_SD<- diversity(Bgm_behaviorcount_month9$count)
Bgm_month9_SD
```

### Averaging the SDs across Bgm's 4 months pre-release
```{r}
Bgm_pre_allSDs<- c(Bgm_month6_SD,Bgm_month7_SD,Bgm_month8_SD,Bgm_month9_SD)
Bgm_pre_avgSDs<- mean(Bgm_pre_allSDs)
Bgm_pre_avgSDs
```

## KOVU
## Filtering out Kovu from the pre-focals dataset
```{r}
Kovu<- pre_focals %>% filter(FOCAL.ID == "KO")
n_distinct(Kovu$FOCAL.REFERENCE.CODE) #55 distinct focals
```

### Getting SD for each month for Kovu during pre-release observations
```{r}
#Month 6
Kovu_behaviorcount_month6<- Kovu %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Kovu_behaviorcount_month6

Kovu_month6_SD<- diversity(Kovu_behaviorcount_month6$count)
Kovu_month6_SD

#Month 7
Kovu_behaviorcount_month7<- Kovu %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Kovu_behaviorcount_month7

Kovu_month7_SD<- diversity(Kovu_behaviorcount_month7$count)
Kovu_month7_SD

#Month 8
Kovu_behaviorcount_month8<- Kovu %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Kovu_behaviorcount_month8

Kovu_month8_SD<- diversity(Kovu_behaviorcount_month8$count)
Kovu_month8_SD

#Month 9
Kovu_behaviorcount_month9<- Kovu %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Kovu_behaviorcount_month9

Kovu_month9_SD<- diversity(Kovu_behaviorcount_month9$count)
Kovu_month9_SD
```

### Averaging the SDs across Kovu's 4 months pre-release
```{r}
Kovu_pre_allSDs<- c(Kovu_month6_SD,Kovu_month7_SD,Kovu_month8_SD,Kovu_month9_SD)
Kovu_pre_avgSDs<- mean(Kovu_pre_allSDs)
Kovu_pre_avgSDs
```

## EDDY
## Filtering out Eddy from the pre-focals dataset
```{r}
Ed<- pre_focals %>% filter(FOCAL.ID == "ED")
n_distinct(Ed$FOCAL.REFERENCE.CODE) #56 distinct focals
```

### Getting SD for each month for Eddy during pre-release observations
```{r}
#Month 6
Ed_behaviorcount_month6<- Ed %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Ed_behaviorcount_month6

Ed_month6_SD<- diversity(Ed_behaviorcount_month6$count)
Ed_month6_SD

#Month 7
Ed_behaviorcount_month7<- Ed %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Ed_behaviorcount_month7

Ed_month7_SD<- diversity(Ed_behaviorcount_month7$count)
Ed_month7_SD

#Month 8
Ed_behaviorcount_month8<- Ed %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Ed_behaviorcount_month8

Ed_month8_SD<- diversity(Ed_behaviorcount_month8$count)
Ed_month8_SD

#Month 9
Ed_behaviorcount_month9<- Ed %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Ed_behaviorcount_month9

Ed_month9_SD<- diversity(Ed_behaviorcount_month9$count)
Ed_month9_SD
```

### Averaging the SDs across Eddy's 4 months pre-release
```{r}
Ed_pre_allSDs<- c(Ed_month6_SD,Ed_month7_SD,Ed_month8_SD,Ed_month9_SD)
Ed_pre_avgSDs<- mean(Ed_pre_allSDs)
Ed_pre_avgSDs
```

## TINKER
## Filtering out Tinker from the pre-focals dataset
```{r}
Tink<- pre_focals %>% filter(FOCAL.ID == "TI")
n_distinct(Tink$FOCAL.REFERENCE.CODE) #56 distinct focals
```

### Getting SD for each month for Tinker during pre-release observations
```{r}
#Month 6
Tink_behaviorcount_month6<- Tink %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Tink_behaviorcount_month6

Tink_month6_SD<- diversity(Tink_behaviorcount_month6$count)
Tink_month6_SD

#Month 7
Tink_behaviorcount_month7<- Tink %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Tink_behaviorcount_month7

Tink_month7_SD<- diversity(Tink_behaviorcount_month7$count)
Tink_month7_SD

#Month 8
Tink_behaviorcount_month8<- Tink %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Tink_behaviorcount_month8

Tink_month8_SD<- diversity(Tink_behaviorcount_month8$count)
Tink_month8_SD

#Month 9
Tink_behaviorcount_month9<- Tink %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Tink_behaviorcount_month9

Tink_month9_SD<- diversity(Tink_behaviorcount_month9$count)
Tink_month9_SD
```

### Averaging the SDs across Tinker's 4 months pre-release
```{r}
Tink_pre_allSDs<- c(Tink_month6_SD,Tink_month7_SD,Tink_month8_SD,Tink_month9_SD)
Tink_pre_avgSDs<- mean(Tink_pre_allSDs)
Tink_pre_avgSDs
```

## BATMAN
## Filtering out Batman from the pre-focals dataset
```{r}
Bat<- pre_focals %>% filter(FOCAL.ID == "BT")
n_distinct(Bat$FOCAL.REFERENCE.CODE) #56 distinct focals
```

### Getting SD for each month for Batman during pre-release observations
```{r}
#Month 6
Bat_behaviorcount_month6<- Bat %>% 
  filter(MONTH == "6") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Bat_behaviorcount_month6

Bat_month6_SD<- diversity(Bat_behaviorcount_month6$count)
Bat_month6_SD

#Month 7
Bat_behaviorcount_month7<- Bat %>% 
  filter(MONTH == "7") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Bat_behaviorcount_month7

Bat_month7_SD<- diversity(Bat_behaviorcount_month7$count)
Bat_month7_SD

#Month 8
Bat_behaviorcount_month8<- Bat %>% 
  filter(MONTH == "8") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Bat_behaviorcount_month8

Bat_month8_SD<- diversity(Bat_behaviorcount_month8$count)
Bat_month8_SD

#Month 9
Bat_behaviorcount_month9<- Bat %>% 
  filter(MONTH == "9") %>%
  group_by(BEHAVIOUR) %>% 
  summarize(count=n()) %>% 
  arrange(desc(count))
Bat_behaviorcount_month9

Bat_month9_SD<- diversity(Bat_behaviorcount_month9$count)
Bat_month9_SD
```

### Averaging the SDs across Batman's 4 months pre-release
```{r}
Bat_pre_allSDs<- c(Bat_month6_SD,Bat_month7_SD,Bat_month8_SD,Bat_month9_SD)
Bat_pre_avgSDs<- mean(Bat_pre_allSDs)
Bat_pre_avgSDs
```

### Creating a table with all of average Shannon Diversity Indices for each individual
```{r}
pre_SDs_table<- matrix(c(Pop_pre_avgSDs, Zip_pre_avgSDs, Jack_pre_avgSDs, Blue_pre_avgSDs, Alex_pre_avgSDs, Bart_pre_avgSDs, Nev_pre_avgSDs, Aug_pre_avgSDs, Amy_pre_avgSDs, May_pre_avgSDs, Toni_pre_avgSDs, Boo_pre_avgSDs, Bgm_pre_avgSDs, Kovu_pre_avgSDs, Ed_pre_avgSDs, Tink_pre_avgSDs, Bat_pre_avgSDs), ncol = 1, byrow = 17)
pre_SDs_table
colnames(pre_SDs_table) <- c("Shannon Diversity Index")
rownames(pre_SDs_table) <- c("Pops","Zip","Jack", "Blue", "Alex", "Bart", "Nev", "Aug", "Amy", "May", "Toni", "Boo", "Bgm", "Kovu", "Eddy", "Tinker", "Batman")
pre_SDs_table<- as.table(pre_SDs_table)
#table(pre_SDs_table) %>% 
        #as.data.frame() %>% 
        #arrange(desc(Freq))
pre_SDs_table

x<- barplot(pre_SDs_table, beside = TRUE, space = c(0.25,1), xlab = "", ylab = "Shannon Diversity Index", names.arg = c("Pops","Zip","Jack", "Blue", "Alex", "Bart", "Nev", "Aug", "Amy", "May", "Toni", "Boo", "Big Mama", "Kovu", "Eddy", "Tinker", "Batman"), ylim = c(0,2.5), cex.names = 0.75, las=2, col="#69b3a2") #I don't love this barplot visual, I can't figure out how to turn the x-axis labels on an angle using a table
x
```


## Creating a DF for the pre-release Shannon Diversity Index values so that I can use the barplot() function more easily
```{r}
Individual<- c("Pops","Zip","Jack", "Blue", "Alex", "Bart", "Nev", "Aug", "Amy", "May", "Toni", "Boo", "Big Mama", "Kovu", "Eddy", "Tinker", "Batman") #my first column
SD<- c(Pop_pre_avgSDs, Zip_pre_avgSDs, Jack_pre_avgSDs, Blue_pre_avgSDs, Alex_pre_avgSDs, Bart_pre_avgSDs, Nev_pre_avgSDs, Aug_pre_avgSDs, Amy_pre_avgSDs, May_pre_avgSDs, Toni_pre_avgSDs, Boo_pre_avgSDs, Bgm_pre_avgSDs, Kovu_pre_avgSDs, Ed_pre_avgSDs, Tink_pre_avgSDs, Bat_pre_avgSDs) #My second column
BD_df<- data.frame(Individual,SD) #Turn into data frame
BD_df

row.names(BD_df)<- c("Pops","Zip","Jack", "Blue", "Alex", "Bart", "Nev", "Aug", "Amy", "May", "Toni", "Boo", "Big Mama", "Kovu", "Eddy", "Tinker", "Batman") #I need to customize my rownames because with the code I use down below to turn the names on an angle I need to use the paste(rownames) function... otherwise they would just be 1,2,3...
row.names(BD_df)

par(mar = c(11, 7, 2, 2) + 0.2) #add room for the rotated labels

end_point = 0.5 + nrow(BD_df) + nrow(BD_df) - 1 #this is the line which does the trick (together with barplot "space = 1" parameter)

barplot(BD_df$SD, col = "#69b3a2", 
        main = "",
        ylab = "Shannon Diversity Index", ylim = c(0,2.5),
        xlab = "",
        space = 0.75)
text(seq(1.5, end_point, by = 2), par("usr")[3]-0.25, 
     srt = 60, adj = 1, xpd = TRUE, #rotate 60 degrees (srt = 60)
     labels = paste(rownames(BD_df)), cex = 0.75)
```




### Creating a table by hand of the confirmed dead/presumed dead/presumed emigrated for males/females/infants
```{r}
info<- matrix(c(7,1,0,4,11,3,3,0,3,0,2,0,21,4,5,4), ncol=4, byrow = T)
rownames(info)<- c("Male", "Female", "Infant", "Totals")
colnames(info)<- c("Released", "Confirmed Dead", "Presumed Dead", "Presumed Emigrated")
info<- as.table(info)
info
```

```{r}
summary<- curl("https://raw.githubusercontent.com/langley1/LWTdata2016/main/Summary%20Table.csv")
summary<- read.csv(summary, header = T)

formattable(summary)

customGreen0 = "#DeF7E9"

customGreen = "#71CA97"

customRed = "#ff7f7f"

formattable(summary, 
            align =c("l","c","c","c","c"), 
            list(`Vervets` = formatter(
              "span", style = ~ style(color = "grey",font.weight = "bold"))
))


```


# **NEW ORGANIZED CODE FOR 2025 MANUSCRIPT**

---
title: "Angley et al. 2016: Post-release survival and behavior of rehabilitated vervet monkeys (*Chlorocebus pygerythrus rufoviridis*) in Malawi"
output: html_document
---
install.packages("curl")
install.packages("dplyr")
install.packages("tidyverse")
install.packages("gplots")
install.packages("corrplot")
install.packages("ggplot2")
install.packages("vegan")
install.packages("data.table")
install.packages("tidyr")
install.packages("formattable")
install.packages("purrr")
install.packages("igraph")
install.packages("EloRating)

```{r}
library(curl)
library(dplyr)
library(tidyverse)
library(gplots)
library(corrplot)
library(ggplot2)
library(vegan)
library(data.table)
library(tidyr)
library(formattable)
library(igraph)
library(purrr)
library(EloRating)
```

## **SOCIAL NETWORK** 
### Pre-release Social Proximity
```{r}
pre_socnet<- curl("https://raw.githubusercontent.com/nickmikulski/Spring2021/main/Pre-release_Social%20Proximity_csv.csv")
pre_socnet<- read.csv(pre_socnet, header = T, na.strings=c(""," ","NA"))
#head(pre_socnet)

pre_socnet_close<- pre_socnet %>% #creating a new dataframe called pre_socnet_close using data from the original pre_socnet dataframe
  filter(Focal.ID != "BT", #this code REMOVES all data that has Batman has the focal ID (BT is wild male from pre-release)
         Association != "BT", #this code REMOVES all data that has Batman in association column
         Proximity.Code %in% c("1","2")) #this code only keeps proximity codes 1,2 (excluding 3,4) because we are focusing on closer proximity) 
#head(pre_socnet_close)
```

#### Creating a matrix
```{r}
# 1. Create a character vector of all the focal IDs in your dataset:
pre_sn_closeIDs<-as.character(unique(pre_socnet_close$Focal.ID))

# 2. Get a list of dataframes, subsetted by monkey ID:
pre_sn_monkeylist<-lapply(pre_sn_closeIDs, function(x){pre_socnet_close[pre_socnet_close[["Focal.ID"]] == x, ]})
#head(pre_sn_monkeylist) #this will load the first 6 lists, take a look at them and see that each is for an individual monkey

# 3. Group each by focal/associate, and count how many times they are observed close together:
pre_sn_grouped<-
  pre_sn_monkeylist %>%
  purrr::map(~group_by(.,Association)) %>%
  purrr::map(~summarize(.,count=n())) 
names(pre_sn_grouped) <- pre_sn_closeIDs #this will give each grouped list the name of the Focal ID

# 4. Set up your pairwise combinations of interacting monkeys:
pre_sn_monkeycombos<-list(focal=pre_sn_closeIDs, associate=pre_sn_closeIDs) #create list of all possible focals/associates
pre_sn_filt<- function(x, y) {x == y} #create function to filter out same-monkey pairs ("PO is close to PO")
pre_sn_combo<- pre_sn_monkeycombos %>% cross_df(.,.filter=pre_sn_filt) #get the filtered combined list as a dataframe
head(pre_sn_combo)

pre_sn_combo2<-
  pre_sn_combo %>%
  mutate(absent1 = map2_chr(
    focal,
    associate,
    ~if_else(.x %in% names(pre_sn_grouped),true="TRUE",false="FALSE"))) %>%
    mutate(absent2 = map2_chr(
    focal,
    associate,
    ~if_else(.y %in% pre_sn_grouped[[.x]]$Association,true="TRUE",false="FALSE"))) %>%
  filter(absent1 == "TRUE") %>%
  filter(absent2 == "TRUE") %>%
  dplyr::select(-absent1,-absent2)

pre_sn_combo3<- pre_sn_combo2 %>% 
  mutate(proximity = map2_int(
    focal, 
    associate, 
    ~pre_sn_grouped %>% pluck(.x) %>% filter(Association==.y) %>% as.data.frame(.) %>% .[,2]))
#pre_sn_combo3

pre_sn_matrix<-spread(pre_sn_combo3,associate,proximity) %>% column_to_rownames(var="focal") %>% data.matrix()
pre_sn_matrix #social proximity matrix between focal and associate 
```

```{r}
pre_sn_codes <- sort(pre_sn_closeIDs)

pre_sn_df <- as.data.frame(pre_sn_matrix, stringsAsFactors = TRUE) #creating the matrix data frame
```

#### Social Network Figures 
```{r}
pre_sortprox<- pre_sn_combo3[order(pre_sn_combo3$proximity),]

pre_sn_edges<- pre_sn_df
pre_sn_vertices<- c(pre_sn_codes)
pre_sn_df2<- as.data.frame(pre_sortprox, stringsAsFactors = TRUE, row.names = pre_sn_vertices)
pre_sn_graph<- graph_from_data_frame(d=pre_sn_df2, vertices = pre_sn_vertices, directed = FALSE)

pre_sn_proximity<- as.numeric(unlist(dplyr::select(pre_sn_combo3, "proximity")))
```

*The figure*
```{r}
par(bg = "white")
pre_social_network_fig<- plot(pre_sn_graph,
      vertex.size = 10,
      vertex.color = "lightgrey",
      vertex.label.color = "black",
      edge.width=((1/50)*(pre_sn_proximity)),
      edge.curved = 0.25)
#pre_social_network_fig
```




#### Adding the total number of focal follows in which proximity info was collected
```{r}
pre_socnet_TOTALS<- curl("https://raw.githubusercontent.com/langley1/LWTdata2016/refs/heads/main/Pre-release_Social%20Proximity.csv")
pre_socnet_TOTALS<- read.csv(pre_socnet_TOTALS, header = T, na.strings=c(""," ","NA")) #loading in data
head(pre_socnet_TOTALS)
```

*Doing it for each individual separately*
```{r}
pre_socnet_TOTALS_AM<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "AM") %>% 
  filter(Association != "OS") %>% #fitering out "out of sight"
  filter(Association != "UK") %>% #filtering out "unknown"
  filter(Association != "BT") %>% #filtering out Batman, the wild male because we remove him from the pairwise matrix above
  mutate(total = n_distinct(FOCAL.REFERENCE)) #adding in new column with the number of distinct focal references for that individual

pre_socnet_TOTALS_ZI<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "ZI") %>% 
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_BA<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "BA") %>% 
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_PO<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "PO") %>%
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_AL<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "AL") %>% 
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_BL<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "BL") %>% 
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_TO<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "TO") %>% 
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_AU<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "AU") %>% 
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_BO<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "BO") %>% 
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_JA<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "JA") %>%
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_MG<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "MG") %>% 
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_ED<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "ED") %>%
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_MA<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "MA") %>% 
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_BM<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "BM") %>% 
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_NE<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "NE") %>% 
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_KO<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "KO") %>% 
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_TI<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "TI") %>% 
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

pre_socnet_TOTALS_BA<- pre_socnet_TOTALS %>%
  filter(Focal.ID == "PA") %>%
  filter(Association != "OS") %>%
  filter(Association != "UK") %>%
  filter(Association != "BT") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 
```

#### Making a matrix with Focial ID, Proximity Association & Total follows
```{r}
pre_socnet_TOTALs_combined<- bind_rows(pre_socnet_TOTALS_AL, pre_socnet_TOTALS_AM, pre_socnet_TOTALS_AU, pre_socnet_TOTALS_BA, pre_socnet_TOTALS_BL, pre_socnet_TOTALS_BM, pre_socnet_TOTALS_BO, pre_socnet_TOTALS_ED, pre_socnet_TOTALS_JA, pre_socnet_TOTALS_KO, pre_socnet_TOTALS_MA, pre_socnet_TOTALS_MG, pre_socnet_TOTALS_NE, pre_socnet_TOTALS_PO,  pre_socnet_TOTALS_TI, pre_socnet_TOTALS_TO, pre_socnet_TOTALS_ZI) #combining the individual dfs

pre_socnet_TOTALs_clean <- pre_socnet_TOTALs_combined %>%
  distinct(Focal.ID, Association, total) #have the clean out the Focal ID /Association duplicates from the table because the total focal number will be the same throughout so we don't need the duplicates

pre_socnet_TOTALs_matrix <- pre_socnet_TOTALs_clean %>% #making it into a pairwise table
  pivot_wider(
    names_from = Association,
    values_from = total,
    values_fill = 0    # fill missing with 0 instead of NA
  )

pre_socnet_TOTALs_matrix <- pre_socnet_TOTALs_matrix %>% 
  column_to_rownames('Focal.ID') #changing Focal ID column into row names

pre_socnet_TOTALs_matrix <- pre_socnet_TOTALs_matrix %>%
  select(AL,AM,AU,BA,BL,BM,BO,ED,JA,KO,MA,MG,NE,PO,TI,TO,ZI) # Specify the new order of column name

pre_socnet_TOTALs_matrix<- as.matrix(pre_socnet_TOTALs_matrix) #turning it into a matrix, has to come after all the other adjustments to the df
```

#### Weighting the proximity counts by the total number of focal follows
```{r}
#Now dividing the proximity matrix by the total number of focals matrix to account for focal count
pre_proximity_rate_matrix <- pre_sn_matrix / pre_socnet_TOTALs_matrix
pre_proximity_rate_matrix[pre_socnet_TOTALs_matrix == 0] <- NA
```

#### Eigenvector centrality using undirected data
```{r}
pre_proximity_rate_clean <- pre_proximity_rate_matrix
pre_proximity_rate_clean[is.na(pre_proximity_rate_clean)] <- 0 #turning NAs into 0s

pre_proximity_rate_undirect <- (pre_proximity_rate_clean + t(pre_proximity_rate_clean)) / 2 
#t() takes the transpose of the matrix so the roles of focal and associate are swapped
#we add the original matrix and the transposed matrix together 
#divide by 2 to get the average of the two directional values to reflect the mutual association strength between individuals, rather than two directional rates

pre_proximity_rate_graph_undirect <- graph_from_adjacency_matrix(
  pre_proximity_rate_undirect, mode = "undirected", weighted = TRUE, diag = FALSE)

#calculating post-release eigenvector centrality with UNDIRECTED relationships (doesn't matter who is focal and who is associate)
pre_eigen_centrality_undirect <- eigen_centrality(pre_proximity_rate_graph_undirect, directed = FALSE, weights = E(pre_proximity_rate_graph_undirect)$weight)

#extracting the scores
pre_eigen_centrality_scores_undirect <- pre_eigen_centrality_undirect$vector
#pre_eigen_centrality_scores_undirect

#putting eigenvector scores back into a df
pre_eigen_centrality_df_undirect <- data.frame(
  Focal.ID = names(pre_eigen_centrality_scores_undirect),
  eigenvector_centrality = pre_eigen_centrality_scores_undirect
)
pre_eigen_centrality_df_undirect
```

### Post-release social proximity
```{r}
post_socnet<- curl("https://raw.githubusercontent.com/nickmikulski/Spring2021/main/Post-release_Social%20Proximity_CSV.csv")
post_socnet<- read.csv(post_socnet, header = T, na.strings=c(""," ","NA"))
#head(post_socnet)

post_socnet_close<- post_socnet %>% #creating a new dataframe called post_socnet_close using data from the original post_socnet dataframe
  filter(Focal.ID != c("BT"), #this code REMOVES all data that has Batman as the focal ID (BT is wild male from prerelease)
         Association != c("BT"), #this code REMOVES all data that has Batman in association column
         Proximity.Code %in% c("1","2") #this code only keeps proximity codes 1,2 (excluding 3,4) because we are focusing on closer proximity
  ) 
#head(post_socnet_close)
```

#### Creating the Matrix
```{r}
# 1. Create a character vector of all the focal IDs in dataset:
post_sn_IDs<-sort(as.character(unique(post_socnet_close$Focal.ID)))
#post_sn_IDs

# 2. Get a list of dataframes, subsetted by monkey ID:
post_sn_monkeylist<-lapply(post_sn_IDs, function(x){post_socnet_close[post_socnet_close[["Focal.ID"]] == x, ]})
# It is creating a separate dataframe for each individual based on their focal id
#head(post_sn_monkeylist)

# 3. Group each by focal/associate, and count how many times they are observed close together:
post_sn_grouped<-
  post_sn_monkeylist %>%
  purrr::map(~group_by(.,Association)) %>%
  purrr::map(~summarize(.,count=n())) 
#post_sn_grouped

names(post_sn_grouped) <- post_sn_IDs #this gives each grouped list the name of the Focal ID
#post_sn_grouped

# 4. Set up pairwise combinations of interacting monkeys:
post_sn_monkeycombos<-list(focal=post_sn_IDs, associate=post_sn_IDs) #create list of all possible focals/associates
post_sn_filtf<- function(x, y) {x == y} #create function to filter out same-monkey pairs ("PO is close to PO")
post_sn_combo<- post_sn_monkeycombos %>% cross_df(.,.filter=post_sn_filtf) #get the filtered combined list as a dataframe
#post_sn_combo
```

```{r}
# 5. Create new dataframes with specific criteria
post_sn_combo2<-
  post_sn_combo %>%
  mutate(absent1 = map2_chr( #new column called "absent1"
    focal,
    associate,
    ~if_else(.x %in% names(post_sn_grouped),true="TRUE",false="FALSE"))) %>%
    mutate(absent2 = map2_chr(
    focal,
    associate,
    ~if_else(.y %in% post_sn_grouped[[.x]]$Association,true="TRUE",false="FALSE"))) %>%
  filter(absent1 == "TRUE") %>%
  filter(absent2 == "TRUE") %>%
  dplyr::select(-absent1,-absent2) #this removes those two new columns you made so you're just left with the ID names

post_sn_combo3<- post_sn_combo2 %>% 
  mutate(proximity = map2_int( #new column called "proximity" that is the count for when proximity code = 1 or 2
    focal, 
    associate, 
    ~post_sn_grouped %>% pluck(.x) %>% filter(Association==.y) %>% as.data.frame(.) %>% .[,2]))
head(post_sn_combo3)

# 6. Create your matrix
post_sn_matrix<-spread(post_sn_combo3,associate,proximity) %>% column_to_rownames(var="focal") %>% data.matrix()
#post_sn_matrix
```

```{r}
post_sn_codes <- sort(post_sn_IDs)

post_sn_df <- as.data.frame(post_sn_matrix, stringsAsFactors = TRUE) #creating the matrix data frame
```

#### Social Network Figures 
```{r}
post_sortprox<- post_sn_combo3[order(post_sn_combo3$proximity),]

post_sn_edges<- post_sn_df
post_sn_vertices<- c(post_sn_codes)
post_sn_df2<- as.data.frame(post_sortprox, stringsAsFactors = TRUE, row.names = post_sn_vertices)
post_sn_graph<- graph_from_data_frame(d=post_sn_df2, vertices = post_sn_vertices, directed = FALSE)

post_sn_proximity<- as.numeric(unlist(dplyr::select(post_sn_combo3, "proximity")))
```

*The figure*
```{r}
par(bg = "white")
post_social_network_fig<- plot(post_sn_graph,
      vertex.size = 10,
      vertex.color = "lightgrey",
      vertex.label.color = "black",
      edge.width=((1/50)*(post_sn_proximity)),
      edge.curved = 0.25)
#post_social_network_fig
```

#### Adding the total number of focal follows in which proximity info was collected
```{r}
post_socnet_TOTALS<- curl("https://raw.githubusercontent.com/langley1/LWTdata2016/refs/heads/main/Post-release%20Social%20Proxmity%20TOTALS.csv")
post_socnet_TOTALS<- read.csv(post_socnet_TOTALS, header = T, na.strings=c(""," ","NA")) #loading in data
head(post_socnet_TOTALS)
```

*Doing it for each individual separately*
```{r}
post_socnet_TOTALS_AM<- post_socnet_TOTALS %>%
  filter(Focal.ID == "AM") %>% 
  filter(Association != "OS") %>% #fitering out "out of sight"
  mutate(total = n_distinct(FOCAL.REFERENCE)) #adding in new column with the number of distinct focal references for that individual

post_socnet_TOTALS_ZI<- post_socnet_TOTALS %>%
  filter(Focal.ID == "ZI") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_PO<- post_socnet_TOTALS %>%
  filter(Focal.ID == "PO") %>%
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_AL<- post_socnet_TOTALS %>%
  filter(Focal.ID == "AL") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_BL<- post_socnet_TOTALS %>%
  filter(Focal.ID == "BL") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_TO<- post_socnet_TOTALS %>%
  filter(Focal.ID == "TO") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_AU<- post_socnet_TOTALS %>%
  filter(Focal.ID == "AU") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_BO<- post_socnet_TOTALS %>%
  filter(Focal.ID == "BO") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_JA<- post_socnet_TOTALS %>%
  filter(Focal.ID == "JA") %>%
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_MG<- post_socnet_TOTALS %>%
  filter(Focal.ID == "MG") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_RE<- post_socnet_TOTALS %>%
  filter(Focal.ID == "RE") %>%
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_ED<- post_socnet_TOTALS %>%
  filter(Focal.ID == "ED") %>%
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_MA<- post_socnet_TOTALS %>%
  filter(Focal.ID == "MA") %>% 
  filter(Association != c("OS","I")) %>% #filtering out "I" for infant
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_SK<- post_socnet_TOTALS %>%
  filter(Focal.ID == "SK") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_BM<- post_socnet_TOTALS %>%
  filter(Focal.ID == "BM") %>% 
  filter(Association != c("OS","I")) %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_NE<- post_socnet_TOTALS %>%
  filter(Focal.ID == "NE") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_KO<- post_socnet_TOTALS %>%
  filter(Focal.ID == "KO") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_TI<- post_socnet_TOTALS %>%
  filter(Focal.ID == "TI") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_CI<- post_socnet_TOTALS %>%
  filter(Focal.ID == "CI") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_HO<- post_socnet_TOTALS %>%
  filter(Focal.ID == "HO") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_PA<- post_socnet_TOTALS %>%
  filter(Focal.ID == "PA") %>%
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 
```

#### Making a matrix with Focial ID, Proximity Association & Total follows
```{r}
post_socnet_TOTALs_combined<- bind_rows(post_socnet_TOTALS_AL, post_socnet_TOTALS_AM, post_socnet_TOTALS_AU, post_socnet_TOTALS_BL, post_socnet_TOTALS_BM, post_socnet_TOTALS_BO, post_socnet_TOTALS_CI, post_socnet_TOTALS_ED, post_socnet_TOTALS_HO, post_socnet_TOTALS_JA, post_socnet_TOTALS_KO, post_socnet_TOTALS_MA, post_socnet_TOTALS_MG, post_socnet_TOTALS_NE, post_socnet_TOTALS_PA, post_socnet_TOTALS_PO, post_socnet_TOTALS_RE, post_socnet_TOTALS_SK, post_socnet_TOTALS_TI, post_socnet_TOTALS_TO, post_socnet_TOTALS_ZI) #combining the individual dfs

post_socnet_TOTALs_clean <- post_socnet_TOTALs_combined %>%
  distinct(Focal.ID, Association, total) #have the clean out the Focal ID /Association duplicates from the table because the total focal number will be the same throughout so we don't need the duplicates

post_socnet_TOTALs_matrix <- post_socnet_TOTALs_clean %>% #making it into a pairwise table
  pivot_wider(
    names_from = Association,
    values_from = total,
    values_fill = 0    # fill missing with 0 instead of NA
  )

post_socnet_TOTALs_matrix <- post_socnet_TOTALs_matrix %>% 
  column_to_rownames('Focal.ID') #changing Focal ID column into row names

post_socnet_TOTALs_matrix <- post_socnet_TOTALs_matrix %>%
  select(AL,AM,AU,BL,BM,BO,CI,ED,HO,JA,KO,MA,MG,NE,PA,PO,RE,SK,TI,TO,ZI) # Specify the new order of column name

post_socnet_TOTALs_matrix<- as.matrix(post_socnet_TOTALs_matrix) #turning it into a matrix, has to come after all the other adjustments to the df
```

#### Trying to account for SURVIVAL OVERLAP across indiviudals in order to make accurate social proximity scores
```{r}
#Now I have to do the matrix math but I need to tell it that if there's an NA in the post_sn_matrix, then it should give an NA in the final matrix 

#creating a daily_effort df: columns with focal ID, date, and n_follows for each focal reference number
post_socnet_TOTALs_combined_withdate<- post_socnet_TOTALs_combined %>%
  mutate(date = as.Date(paste(Year, Month, Day, sep = "-"))) %>% #
  group_by(Focal.ID, date) %>%
  summarise(
    n_follows = n_distinct(FOCAL.REFERENCE),
    .groups = "drop"
  )

#checking to see the total number of focal follows per individual 
post_socnet_TOTALs_combined_withdate %>%
  group_by(Focal.ID) %>%
  summarise(total_follows = sum(n_follows))

# df_alive: ID, start_date, end_date
post_socnet_TOTALs_alive<- post_socnet_TOTALs_combined_withdate %>%
  group_by(Focal.ID) %>%
  summarise(
    start_date = as.Date("2016-3-18"),
    end_date   = max(date),
    .groups = "drop"
  )

post_socnet_TOTALs_alive <- post_socnet_TOTALs_alive %>% #manually editing the end date for the indiviudals based on whether they survived or died (got this date from supp material table)
  mutate(
    end_date = case_when(
      Focal.ID %in% c("PO","BL","AM","ED","KO","MA","MY","CI","HO") ~ as.Date("2016-12-15"),  
      Focal.ID == "AL" ~ as.Date("2016-11-18"),
      Focal.ID == "TO" ~ as.Date("2016-08-23"),
      Focal.ID == "ZI" ~ as.Date("2016-03-22"),
      Focal.ID == "AU" ~ as.Date("2016-12-08"),
      Focal.ID == "BO" ~ as.Date("2016-10-08"),
      Focal.ID == "JA" ~ as.Date("2016-06-11"),
      Focal.ID == "MG" ~ as.Date("2016-08-23"),
      Focal.ID == "RE" ~ as.Date("2016-10-14"),
      Focal.ID == "SK" ~ as.Date("2016-11-23"),
      Focal.ID == "BM" ~ as.Date("2016-09-30"),
      Focal.ID == "NE" ~ as.Date("2016-08-13"),
      Focal.ID == "TI" ~ as.Date("2016-08-30"),
      Focal.ID == "PA" ~ as.Date("2016-10-25"),
    )
  )

#1. create pairwise table (focal, associate)
ids <- post_socnet_TOTALs_alive$Focal.ID
pairs <- expand.grid(focal = ids, associate = ids, stringsAsFactors = FALSE) %>% as_tibble()

#2. join associate alive-range to daily effort rows and filter dates when associate is alive
# First ensure daily effort df has Focal.ID and date
denom_by_pair <- post_socnet_TOTALs_combined_withdate %>%
  rename(focal = Focal.ID) %>%
  # join pairs to allow filtering by each associate's alive range:
  left_join(pairs, by = "focal") %>%          # now each row repeats for each associate
  left_join(post_socnet_TOTALs_alive %>% rename(associate = Focal.ID,
                               assoc_start = start_date,
                               assoc_end = end_date),
            by = "associate") %>%
  filter(date >= assoc_start & date <= assoc_end) %>%
  group_by(focal, associate) %>%
  summarise(total_focal_follows_when_assoc_alive = sum(n_follows, na.rm = TRUE), .groups = "drop")

#3. turn into matrix aligned to our proximity matrix (post_sn_matrix)
denom_mat2 <- denom_by_pair %>%
  pivot_wider(names_from = associate, values_from = total_focal_follows_when_assoc_alive, values_fill = 0) %>%
  column_to_rownames("focal") %>%
  as.matrix()

#Now dividing the proximity matrix by our "days alive overlap" matrix
proximity_rate_matrix <- post_sn_matrix / denom_mat2
proximity_rate_matrix[denom_mat2 == 0] <- NA
```

The rate (or probability) that associate individual was seen in close proximity during a focal follow of X individual, conditional on both being alive at the same time (the wild immigrant males are still part of both of these matrices but we are not getting eigenvector scores for them).

#### Calculating Post-Release Eigenvector Centrality Scores (using proximity rate data) using undirected data
```{r}
proximity_rate_clean <- proximity_rate_matrix
proximity_rate_clean[is.na(proximity_rate_clean)] <- 0 #turning NAs into 0s

proximity_rate_undirect <- (proximity_rate_clean + t(proximity_rate_clean)) / 2 
#t() takes the transpose of the matrix so the roles of focal and associate are swapped
#we add the original matrix and the transposed matrix together 
#divide by 2 to get the average of the two directional values to reflect the mutual association strength between individuals, rather than two directional rates

proximity_rate_graph_undirect <- graph_from_adjacency_matrix(
  proximity_rate_undirect, mode = "undirected", weighted = TRUE, diag = FALSE)

#calculating post-release eigenvector centrality with UNDIRECTED relationships (doesn't matter who is focal and who is associate)
post_eigen_centrality_undirect <- eigen_centrality(proximity_rate_graph_undirect, directed = FALSE, weights = E(proximity_rate_graph_undirect)$weight)

#extracting the scores
post_eigen_centrality_scores_undirect <- post_eigen_centrality_undirect$vector
post_eigen_centrality_scores_undirect

#putting eigenvector scores back into a df
post_eigen_centrality_df_undirect <- data.frame(
  Focal.ID = names(post_eigen_centrality_scores_undirect),
  eigenvector_centrality = post_eigen_centrality_scores_undirect
)
post_eigen_centrality_df_undirect
```

The edge in this undirected case means "relationship" rather than "interaction direction" because we want a pairwise association strength, not a directional interaction. 

## **SURVIVAL ANALYSIS**
### Post-release only (no deaths pre-release)
```{r}
#STEP 1:
post_focals_surv<- curl("https://raw.githubusercontent.com/langley1/LWTdata2016/main/2016_post-release_focals_SURV.csv") #inputting my post focals dataset with data in my "Date End" column 
post_focals_surv<- read.csv(post_focals_surv, header = T, na.strings=c(""," ","NA"))

#STEP 2:
post_focals_surv$Date.End <- as.Date(post_focals_surv$Date.End, format = "%Y-%m-%d") #telling R that my "Date End" column is in the y-m-d format and that it needs to be read as "Date" rather than "Factor"

post_focals_surv<- post_focals_surv %>% 
  unite(Date, c(DAY, MONTH, YEAR), sep = "-", remove = FALSE) %>% #Creating a new column called "Date" using unite(), which combines Day, Month, and Year columns with - as separator
  mutate(Date = as.Date(Date, format = "%d-%m-%Y")) #using mutate() to turn my date column into acceptable "date" format. NOTE: the format I use in this code is what format my original column IS in...R then turns it into standard Y-M-D format, which will match my "Date End" column 

#STEP 3:
post_focals_surv<- post_focals_surv %>% filter(!FOCAL.ID %in% c("CI","HO","PA","ZI")) %>% #filtering out these individuals because they are wild males
  droplevels() %>% #takes the IDs I want to remove from the levels as well 
  group_by(FOCAL.ID) %>%
  mutate( #creating a new column called "days_surv"
    days_surv = 
      as.numeric( 
        difftime(Date.End[1], #only selecting the first cell in "Date.End" and "Date" so that it calcultes the difference from the first day of data collection to the day I entered into "Date.End", which is the last day they were observed
                 Date[1],
                 units = "days"))) #number of days survived

#STEP 4: status 1 = survived or emigrated; status 2 = confirmed or assumed dead
post_focals_surv<- post_focals_surv %>% 
  mutate(status = #creating a new column called "status" to label individuals who die vs those who survive
    case_when(FOCAL.ID %in% c("PO","MG","BL","AM","KO","ED","MA") ~ as.numeric(1), #for these individuals status=1
              FOCAL.ID %in% c("JA","NE","AL","TO","AU","BO","BM","TI","SK","RE") ~ as.numeric(2))) #for these individuals status=2

#STEP 5: select only the first row for each focal ID and clean up dataframe
post_surv_edited<-
post_focals_surv %>% 
  group_by(FOCAL.ID) %>% 
  filter(row_number()==1) #only takes the first row

drop <- c("ASSOCIATION", "OBSERVER.1","OBSERVER.2","WEATHER","TEMP","ESTRUS","FOCAL.PERIOD","FOCAL.MINUTE","BEHAVIOUR","BEHAVIOUR.2","FOOD.TYPE","FOOD.Type.2","POSITION.IN.CANOPY","Position2","Position3","PLANT.SPECIES","PLANT.SPECIES.SAT.ON","G.P.S..Location","X","NOteS") #these are all the extra columns I just don't need
post_surv_edited = post_surv_edited[,!(names(post_surv_edited) %in% drop)]

post_surv_edited[17,14] = as.numeric(228) #manually changing Skittles days_surv number since he only has one focal in April, so his number needed to be changed
```

*Adding in Centrality Scores*
```{r}
post_surv_edited_with_centrality<- post_surv_edited %>%
  mutate(Date = as.Date("2016-03-18")) %>% #the start of the post-release period
  mutate(Date.End = #adding in the unique end date for each individual (death, emigration, or end of study)
           case_when(FOCAL.ID == "PO" ~ as.Date("2016-12-15"),
                     FOCAL.ID == "BL" ~ as.Date("2016-12-15"),
                     FOCAL.ID == "AM" ~ as.Date("2016-12-15"),
                     FOCAL.ID == "ED" ~ as.Date("2016-12-15"),
                     FOCAL.ID == "MA" ~ as.Date("2016-12-15"),
                     FOCAL.ID == "KO" ~ as.Date("2016-12-15"),
                     FOCAL.ID == "AL" ~ as.Date("2016-11-18"),
                     FOCAL.ID == "TO" ~ as.Date("2016-08-23"),
                     FOCAL.ID == "AU" ~ as.Date("2016-12-08"),
                     FOCAL.ID == "BO" ~ as.Date("2016-10-08"),
                     FOCAL.ID == "JA" ~ as.Date("2016-06-11"),
                     FOCAL.ID == "MG" ~ as.Date("2016-08-23"),
                     FOCAL.ID == "RE" ~ as.Date("2016-10-04"),
                     FOCAL.ID == "SK" ~ as.Date("2016-11-23"),
                     FOCAL.ID == "BM" ~ as.Date("2016-09-30"),
                     FOCAL.ID == "NE" ~ as.Date("2016-08-13"),
                     FOCAL.ID == "TI" ~ as.Date("2016-08-30"))) %>%
  mutate(David_scores_post = #Adding in a column for the post_release david's scores
           case_when(FOCAL.ID == "PO" ~ as.numeric(9.854), #from post_ds_results
              FOCAL.ID == "BL" ~ as.numeric(8.932),
              FOCAL.ID == "AM" ~ as.numeric(8.696),
              FOCAL.ID == "AL" ~ as.numeric(8.691),
              FOCAL.ID == "TO" ~ as.numeric(8.211),
              FOCAL.ID == "AU" ~ as.numeric(7.404),
              FOCAL.ID == "BO" ~ as.numeric(7.270),
              FOCAL.ID == "JA" ~ as.numeric(8.181),
              FOCAL.ID == "MG" ~ as.numeric(7.696),
              FOCAL.ID == "RE" ~ as.numeric(7.672),
              FOCAL.ID == "ED" ~ as.numeric(7.518),
              FOCAL.ID == "MA" ~ as.numeric(7.357),
              #FOCAL.ID == "SK" ~ as.character("NA"),
              FOCAL.ID == "BM" ~ as.numeric(8.132),
              FOCAL.ID == "NE" ~ as.numeric(7.826),
              FOCAL.ID == "KO" ~ as.numeric(6.434)),
              #FOCAL.ID == "TI" ~ as.numeric()),
         proxcent_number = 
           case_when(FOCAL.ID == "PO" ~ as.numeric(39),
              FOCAL.ID == "BL" ~ as.numeric(38),
              FOCAL.ID == "AM" ~ as.numeric(40),
              FOCAL.ID == "AL" ~ as.numeric(39),
              FOCAL.ID == "TO" ~ as.numeric(37),
              FOCAL.ID == "AU" ~ as.numeric(40),
              FOCAL.ID == "BO" ~ as.numeric(36),
              FOCAL.ID == "JA" ~ as.numeric(34),
              FOCAL.ID == "MG" ~ as.numeric(38),
              FOCAL.ID == "RE" ~ as.numeric(32),
              FOCAL.ID == "ED" ~ as.numeric(39),
              FOCAL.ID == "MA" ~ as.numeric(38),
              FOCAL.ID == "SK" ~ as.numeric(27),
              FOCAL.ID == "BM" ~ as.numeric(36),
              FOCAL.ID == "NE" ~ as.numeric(37),
              FOCAL.ID == "KO" ~ as.numeric(39),
              FOCAL.ID == "TI" ~ as.numeric(36)),
         proxcent_number2 = 
           case_when(FOCAL.ID == "PO" ~ as.numeric(1.00),
              FOCAL.ID == "BL" ~ as.numeric(0.924),
              FOCAL.ID == "AM" ~ as.numeric(0.928),
              FOCAL.ID == "AL" ~ as.numeric(0.874),
              FOCAL.ID == "TO" ~ as.numeric(0.461),
              FOCAL.ID == "AU" ~ as.numeric(0.904),
              FOCAL.ID == "BO" ~ as.numeric(0.682),
              FOCAL.ID == "JA" ~ as.numeric(0.199),
              FOCAL.ID == "MG" ~ as.numeric(0.566),
              FOCAL.ID == "RE" ~ as.numeric(0.400),
              FOCAL.ID == "ED" ~ as.numeric(0.841),
              FOCAL.ID == "MA" ~ as.numeric(0.727),
              FOCAL.ID == "SK" ~ as.numeric(0.401),
              FOCAL.ID == "BM" ~ as.numeric(0.715),
              FOCAL.ID == "NE" ~ as.numeric(0.486),
              FOCAL.ID == "KO" ~ as.numeric(0.895),
              FOCAL.ID == "TI" ~ as.numeric(0.418)),
        NEW_eigencent_scores_2025 = 
           case_when(FOCAL.ID == "PO" ~ as.numeric(0.7986232), #manually adding in the new eigenvector centrality scores from post_eigen_centrality_df_undirect
              FOCAL.ID == "BL" ~ as.numeric(0.8880804),
              FOCAL.ID == "AM" ~ as.numeric(0.9748237),
              FOCAL.ID == "AL" ~ as.numeric(0.8409673),
              FOCAL.ID == "TO" ~ as.numeric(0.6292328),
              FOCAL.ID == "AU" ~ as.numeric(1.0000000),
              FOCAL.ID == "BO" ~ as.numeric(0.7488248),
              FOCAL.ID == "JA" ~ as.numeric(0.3612819),
              FOCAL.ID == "MG" ~ as.numeric(0.4971380),
              FOCAL.ID == "RE" ~ as.numeric(0.5718587),
              FOCAL.ID == "ED" ~ as.numeric(0.8666694),
              FOCAL.ID == "MA" ~ as.numeric(0.7496980),
              FOCAL.ID == "SK" ~ as.numeric(0.4391937),
              FOCAL.ID == "BM" ~ as.numeric(0.7950169),
              FOCAL.ID == "NE" ~ as.numeric(0.5963072),
              FOCAL.ID == "KO" ~ as.numeric(0.9478891),
              FOCAL.ID == "TI" ~ as.numeric(0.5414905)))

#Adding Zip into the df manually because he got filterd out by accident prior
post_surv_edited_with_centrality <- post_surv_edited_with_centrality %>%
  ungroup() %>%
  add_row(RELEASE = "POST", Date = as.Date("2016-03-18"), FOCAL.ID = "ZI", SEX = "M", AGE = "A", Date.End = as.Date("2016-03-22"), status = as.numeric(1), NEW_eigencent_scores_2025 = as.numeric(0.2907479))

post_surv_edited_with_centrality <- post_surv_edited_with_centrality %>%
  mutate(NEW_days_alive = as.numeric(Date.End - Date) + 1) #calculating a new # of days survived column
```

#### Survival Probability and curves with Kaplan-Meier
```{r}
Surv(post_surv_edited_with_centrality$NEW_days_alive, post_surv_edited_with_centrality$status)[1:18] #Surv() creates a survival object for use as the response in a model formula. There will be one entry for each subject that is the survival time, which is followed by a + if the subject was censored (in this case, survived or emigrated)

#Survival curves
survfit_all_NEW <- survfit(Surv(NEW_days_alive, status) ~ 1, data = post_surv_edited_with_centrality) #Survfit() creates survival curves based on a formula. Lets generate the overall survival curve for the entire cohort and look at the names
names(survfit_all) #important names are "surv" and "time"
summary(survfit_all)

#To get median survival days
survfit_all<- survfit(Surv(NEW_days_alive, status) ~ 1, data = post_surv_edited_with_centrality) #The median survival days is 251

#Now let's check the probability of surviving until the end of the observations
summary(survfit(Surv(NEW_days_alive, status) ~ 1, data = post_surv_edited_with_centrality), times = 273) #shows us that the probability of survival at the end of data collection is 38%

#Now let's check the probability of surviving halfway through
summary(survfit(Surv(NEW_days_alive, status) ~ 1, data = post_surv_edited_with_centrality), times = 136) #shows us that the probability of surviving halfway is 94%

#Now let's plot survfit object: Horizontal lines represent survival duration for the interval, The height of vertical lines show the change in cumulative probability, Censored observations are indicated by tick marks
plot(survfit(Surv(NEW_days_alive, status) ~ 1, data = post_surv_edited_with_centrality), mark.time = TRUE, 
     xlab = "Days", 
     ylab = "Overall survival probability")

ggsurvplot(
    fit = survfit(Surv(NEW_days_alive, status) ~ 1, data = post_surv_edited_with_centrality), 
    xlab = "Days", 
    ylab = "Overall survival probability")

SURVIVAL_PLOT<- ggsurvplot(survfit_all,
          pval = TRUE, conf.int = TRUE,
          risk.table = TRUE, # Add risk table
          risk.table.col = "strata", # Change risk table color by groups
          #linetype = "strata", # Change line type by groups
          surv.median.line = "hv", # Specify median survival
          ggtheme = theme_bw()) # Change ggplot2 theme
          #palette = c("#E7B800", "#2E9FDF"))
ggsave("SURVIVAL_PLOT.pdf", height = 3, width = 7, last_plot())

#Survfit across Sex
survfit_sex<- survfit(Surv(NEW_days_alive, status) ~ SEX, data = post_surv_edited_with_centrality)
survfit_sex
summary(survfit_sex) #median survival time for females is 256 and 251 for males
summary(survfit_sex)$table
```

*Log-Rank Test*
```{r}
#Differences in survival times between sexes
survdiff(Surv(NEW_days_alive, status) ~ SEX, data = post_surv_edited_with_centrality)

#Differences in survival times between ages
survdiff(Surv(NEW_days_alive, status) ~ AGE, data = post_surv_edited_with_centrality)

#Differences in survival times across the ranks
survdiff(Surv(NEW_days_alive, status) ~ David_scores_post, data = post_surv_edited_with_centrality)

#Differences in survival times across the social proximity numbers
survdiff(Surv(NEW_days_alive, status) ~ NEW_eigencent_scores_2025, data = post_surv_edited_with_centrality)
```

*Cox Multiple regression*
```{r}
#Cox proportional hazards for davids scores
coxph(Surv(NEW_days_alive, status) ~ David_scores_post, data = post_surv_edited_with_centrality)

#Cox proportional hazards for eigenvector centrality
coxph(Surv(NEW_days_alive, status) ~ NEW_eigencent_scores_2025, data = post_surv_edited_with_centrality)

#Cox multiple for davids, sex, and age
NEW_cox_multi1<- coxph(Surv(NEW_days_alive, status) ~ David_scores_post + SEX + AGE, data= post_surv_edited_with_centrality)
summary(NEW_cox_multi1)

#Adding in social prox eigenvector scores
NEW_cox_multi2<- coxph(Surv(NEW_days_alive, status) ~ David_scores_post + SEX + AGE + NEW_eigencent_scores_2025, data= post_surv_edited_with_centrality)
summary(NEW_cox_multi2)

#Need to create a predator vigilance df
NEW_surv_pred<- post_surv_edited %>%
  filter(!FOCAL.ID %in% c("RE","SK")) %>% #these two have very little behavior data post-release so removing them
  droplevels() %>%
  mutate(pred_post = 
           case_when(FOCAL.ID == "PO" ~ as.numeric(7.41), #Taking the mean predator counts from Pops_budget4 df and inputting them here manually
                     FOCAL.ID == "BL" ~ as.numeric(6.78),
                     FOCAL.ID == "AM" ~ as.numeric(6.99),
                     FOCAL.ID == "AL" ~ as.numeric(5.77),
                     FOCAL.ID == "BO" ~ as.numeric(6.82),
                     FOCAL.ID == "BM" ~ as.numeric(6.91),
                     FOCAL.ID == "AU" ~ as.numeric(5.77),
                     FOCAL.ID == "ED" ~ as.numeric(6.10),
                     FOCAL.ID == "JA" ~ as.numeric(7.32),
                     FOCAL.ID == "TI" ~ as.numeric(5.79),
                     FOCAL.ID == "KO" ~ as.numeric(5.27),
                     FOCAL.ID == "MG" ~ as.numeric(4.07),
                     FOCAL.ID == "MA" ~ as.numeric(5.36),
                     FOCAL.ID == "TO" ~ as.numeric(6.13),
                     FOCAL.ID == "NE" ~ as.numeric(7.82),
                     FOCAL.ID == "ZI" ~ as.numeric(0.682)),
         pred_pre = #taking the mean predator counts from Pops_budget2 df and putting them here
           case_when(FOCAL.ID == "PO" ~ as.numeric(12.23),
                     FOCAL.ID == "BL" ~ as.numeric(9.22),
                     FOCAL.ID == "AM" ~ as.numeric(9.32),
                     FOCAL.ID == "AL" ~ as.numeric(8.76),
                     FOCAL.ID == "BO" ~ as.numeric(9.33),
                     FOCAL.ID == "BM" ~ as.numeric(9.88),
                     FOCAL.ID == "AU" ~ as.numeric(8.83),
                     FOCAL.ID == "ED" ~ as.numeric(8.17),
                     FOCAL.ID == "JA" ~ as.numeric(9.84),
                     FOCAL.ID == "TI" ~ as.numeric(8.66),
                     FOCAL.ID == "KO" ~ as.numeric(8.04),
                     FOCAL.ID == "MG" ~ as.numeric(8.53),
                     FOCAL.ID == "MA" ~ as.numeric(7.23),
                     FOCAL.ID == "TO" ~ as.numeric(8.89),
                     FOCAL.ID == "NE" ~ as.numeric(8.35),
                     FOCAL.ID == "ZI" ~ as.numeric(10.17)))

#Adding in the pred column in NEW_surv_pred into post_surv_edited_with_centrality
post_surv_edited_with_centrality_with_pred <- post_surv_edited_with_centrality %>%
  left_join(NEW_surv_pred %>% select(FOCAL.ID, pred_post, pred_pre), by = "FOCAL.ID")

#Not sure why Zip's pred_pre is still showing NA even though I assigned him a number, just going to do it manually: 
post_surv_edited_with_centrality_with_pred[nrow(post_surv_edited_with_centrality_with_pred), ncol(post_surv_edited_with_centrality_with_pred)] <- 10.17

#Cox multiple for Davids scores, sex, age, and predator POST, and social proximity
NEW_cox_multi3<- coxph(Surv(NEW_days_alive, status) ~ David_scores_post + SEX + AGE + pred_post + NEW_eigencent_scores_2025, data= post_surv_edited_with_centrality_with_pred )
summary(NEW_cox_multi3)

coxph(Surv(NEW_days_alive, status) ~ pred_pre, data = post_surv_edited_with_centrality_with_pred)

coxph(Surv(NEW_days_alive, status) ~ pred_post, data = post_surv_edited_with_centrality_with_pred)

#Trying the cox multiple regression models without sex: 
NEW_cox_multi4<- coxph(Surv(NEW_days_alive, status) ~ David_scores_post + AGE + NEW_eigencent_scores_2025, data= post_surv_edited_with_centrality)
summary(NEW_cox_multi4)

NEW_cox_multi5<- coxph(Surv(NEW_days_alive, status) ~ David_scores_post + AGE + pred_post + NEW_eigencent_scores_2025, data= post_surv_edited_with_centrality_with_pred )
summary(NEW_cox_multi5)
#The significant results are the same 
```

*Proportional Hazards Assumption Test and other statistical tests*
```{r}
#Testing for proportional hazards (PH) assumption:
NEW_test.ph<- cox.zph(NEW_cox_multi2)
NEW_test.ph #great, not significant for the model as a whole

#ggcoxzph(NEW_test.ph)

#Testing influential observations 

#Specifying the argument type = dfbeta, plots the estimated changes in the regression coefficients upon deleting each observation in turn
NEW_InfluenceObs<- ggcoxdiagnostics(NEW_cox_multi2, type = "dfbeta",
                 linear.predictions = FALSE, ggtheme = theme_bw()) #I think sex is slightly influential because it appears to have an outlier 
ggsave("InfluenceObs.pdf", width = 8, height= 5, last_plot())

#The deviance residual is a normalized transform of the martingale residual. These residuals should be roughly symmetrically distributed about zero with a standard deviation of 1. Positive values correspond to individuals that died too soon compared to expected survival times. Negative values correspond to individual that lived too long. Very large or small values are outliers, which are poorly predicted by the model.
ggcoxdiagnostics(NEW_cox_multi2, type = "deviance",
                 linear.predictions = FALSE, ggtheme = theme_bw()) #this looks fairly symmetrical around 0 but not perfect
```

METHODS: Proportional hazards (PH) assumption was tested for the model as a whole as well as each covariate based on scaled Schoenfeld residuals to test for independence between residuals and time. Influential observations were also observed graphically using df beta.

RESULTS: The PH assumption test is not statistically significance for the global test. A graphed diagnostic, which shows graphs of the scaled Schoenfeld residuals against the transformed time, shows no trend in the covariates across time. Therefore, we can assume proportional hazards.