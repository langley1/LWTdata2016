---
title: "2016 Post-Release Data"
output: html_document
---

```{r}
library(purrr)#needed for creating social proximity matrix
library(dplyr)
library(tidyr)
library(igraph)
```

# Full Post-Release Dataset

## Importing the dataset
```{r}
post_focals<- curl("https://raw.githubusercontent.com/langley1/LWTdata2016/main/2016_post-release_focals_FULL.csv") #this is FULL dataset
post_focals<- read.csv(post_focals, header = T, na.strings=c(""," ","NA"))
levels(post_focals$BEHAVIOUR)[levels(post_focals$BEHAVIOUR) == "F"] <- "FE" #changing the Fs to FEs
unique(post_focals$BEHAVIOUR)
head(post_focals)

post_focals_observers<- post_focals %>%
  gather("X","Observers", 9:10, na.rm= T)
unique(post_focals_observers$Observers)

post_cont<- curl("https://raw.githubusercontent.com/langley1/LWTdata2016/main/2016_post-release_cont_FULL.csv")
post_cont<- read.csv(post_cont, header = T, na.strings=c(""," ","NA"))
head(post_cont)
```

*Editing Continuous dataset*
```{r}
post_cont<- post_cont %>%
  filter(!ASSOCIATION %in% c("BB","MY","MT","I","ZI"), #removing the infants from association because they were never observed as focals and have very little data in general
         FOCAL.ID != "ZI") #removing ZI because he has very little data and left a few days after release

#Stage 1 post-release
post_cont_1<- post_cont %>%
  filter(MONTH %in% c("4","5")) #looking at the first two full months post-release to assess dominance heirarchy and rank, month 3 was removed to give an adjustment period (this is all before the first individual dies, Jack)
  
#Stage 2 post-release
post_cont_2<- post_cont %>%
  filter(MONTH %in% c("6","7","8"))

#Stage 3 post-release
post_cont_3<- post_cont %>%
  filter(MONTH %in% c("9","10","11"))
```

## Post-Release Rank Determination

### For stage 1
*Combining displacement, agression, and threat into one matrix (focal WINS all of these interactions)*
```{r}
# 1. Create a character vector of all the monkey IDs in your dataset:
post_monkeyIDs1<-as.character(unique(post_cont_1$FOCAL.ID))

# 2. Get a list of dataframes, subsetted by monkey ID:
post_monkey.prelim1<-lapply(post_monkeyIDs1, function(x){post_cont_1[post_cont_1[["FOCAL.ID"]] == x, ]})
head(post_monkey.prelim1)

post_monkey_ALL.prelim1<-
  post_monkey.prelim1 %>%
  purrr::map(~filter(.,BEHAVIOUR %in% c("A+","A-","MP+", "TH+","TH-"), CONFLICT.OUTCOME=="1")) %>% 
  purrr::map(~group_by(.,ASSOCIATION)) %>%
  purrr::map(~summarize(.,count=n()))
names(post_monkey_ALL.prelim1) <- post_monkeyIDs1

post_monkeylist1<-list(actor=post_monkeyIDs1,recipient=post_monkeyIDs1) #create list of all possible actors/recipients
post_filt1 <- function(x, y) {x == y} #create function to filter out same-monkey pairs ("FZ grooms FZ")
post_combo1 <- post_monkeylist1 %>% cross_df(.,.filter=post_filt1) #get the filtered combined list as a dataframe

post_combo_ALL1<-
  post_combo1 %>%
  mutate(absent1 = map2_chr(
    actor,
    recipient,
    ~if_else(.x %in% names(post_monkey_ALL.prelim1),true="TRUE",false="FALSE"))) %>%
    mutate(absent2 = map2_chr(
    actor,
    recipient,
    ~if_else(.y %in% post_monkey_ALL.prelim1[[.x]]$ASSOCIATION,true="TRUE",false="FALSE"))) %>%
  filter(absent1 == "TRUE") %>%
  filter(absent2 == "TRUE") %>%
  dplyr::select(-absent1,-absent2)

post_ALL1<-post_combo_ALL1 %>% 
  mutate(interaction = map2_int(
    actor, 
    recipient, 
    ~post_monkey_ALL.prelim1 %>% pluck(.x) %>% filter(ASSOCIATION==.y) %>% as.data.frame(.) %>% .[,2]))
post_ALL1

post_ALL_matrix1<-spread(post_ALL1,recipient,interaction) %>% column_to_rownames(var="actor") %>% data.matrix()
post_ALL_matrix1
```

*Combining displacement, agression, and threat into one matrix (focal LOSES all of these interactions)*
```{r}
post_monkey_ALL.prelim1_lose<-
  post_monkey.prelim1 %>%
  purrr::map(~filter(.,BEHAVIOUR %in% c("A+","A-","MP+", "TH+","TH-"), CONFLICT.OUTCOME=="2")) %>% 
  purrr::map(~group_by(.,ASSOCIATION)) %>%
  purrr::map(~summarize(.,count=n()))
names(post_monkey_ALL.prelim1_lose) <- post_monkeyIDs1

post_combo_ALL1_lose<-
  post_combo1 %>%
  mutate(absent1 = map2_chr(
    actor,
    recipient,
    ~if_else(.x %in% names(post_monkey_ALL.prelim1_lose),true="TRUE",false="FALSE"))) %>%
    mutate(absent2 = map2_chr(
    actor,
    recipient,
    ~if_else(.y %in% post_monkey_ALL.prelim1_lose[[.x]]$ASSOCIATION,true="TRUE",false="FALSE"))) %>%
  filter(absent1 == "TRUE") %>%
  filter(absent2 == "TRUE") %>%
  dplyr::select(-absent1,-absent2)

post_ALL1_lose<-post_combo_ALL1_lose %>% 
  mutate(interaction = map2_int(
    actor, 
    recipient, 
    ~post_monkey_ALL.prelim1_lose %>% pluck(.x) %>% filter(ASSOCIATION==.y) %>% as.data.frame(.) %>% .[,2]))
post_ALL1_lose

post_ALL_matrix1_lose<-spread(post_ALL1_lose,recipient,interaction) %>% column_to_rownames(var="actor") %>% data.matrix()
post_ALL_matrix1_lose
```

### For stage 2
*Combining displacement, agression, and threat into one matrix (focal WINS all of these interactions)*
```{r}
post_monkeyIDs2<-as.character(unique(post_cont_2$FOCAL.ID))

post_monkey.prelim2<-lapply(post_monkeyIDs2, function(x){post_cont_2[post_cont_2[["FOCAL.ID"]] == x, ]})
head(post_monkey.prelim2)

post_monkey_ALL.prelim2<-
  post_monkey.prelim2 %>%
  purrr::map(~filter(.,BEHAVIOUR %in% c("A+","A-","MP+", "TH+","TH-"), CONFLICT.OUTCOME=="1")) %>% 
  purrr::map(~group_by(.,ASSOCIATION)) %>%
  purrr::map(~summarize(.,count=n()))
names(post_monkey_ALL.prelim2) <- post_monkeyIDs2

post_monkeylist2<-list(actor=post_monkeyIDs2,recipient=post_monkeyIDs2) #create list of all possible actors/recipients
post_filt2 <- function(x, y) {x == y} #create function to filter out same-monkey pairs ("FZ grooms FZ")
post_combo2 <- post_monkeylist2 %>% cross_df(.,.filter=post_filt2) #get the filtered combined list as a dataframe

post_combo_ALL2<-
  post_combo2 %>%
  mutate(absent1 = map2_chr(
    actor,
    recipient,
    ~if_else(.x %in% names(post_monkey_ALL.prelim2),true="TRUE",false="FALSE"))) %>%
    mutate(absent2 = map2_chr(
    actor,
    recipient,
    ~if_else(.y %in% post_monkey_ALL.prelim2[[.x]]$ASSOCIATION,true="TRUE",false="FALSE"))) %>%
  filter(absent1 == "TRUE") %>%
  filter(absent2 == "TRUE") %>%
  dplyr::select(-absent1,-absent2)

post_ALL2<-post_combo_ALL2 %>% 
  mutate(interaction = map2_int(
    actor, 
    recipient, 
    ~post_monkey_ALL.prelim2 %>% pluck(.x) %>% filter(ASSOCIATION==.y) %>% as.data.frame(.) %>% .[,2]))
post_ALL2

post_ALL_matrix2<-spread(post_ALL2,recipient,interaction) %>% column_to_rownames(var="actor") %>% data.matrix()
post_ALL_matrix2
```

*Combining displacement, agression, and threat into one matrix (focal LOSES all of these interactions)*
```{r}
post_monkey_ALL.prelim2_lose<-
  post_monkey.prelim2 %>%
  purrr::map(~filter(.,BEHAVIOUR %in% c("A+","A-","MP+", "TH+","TH-"), CONFLICT.OUTCOME=="2")) %>% 
  purrr::map(~group_by(.,ASSOCIATION)) %>%
  purrr::map(~summarize(.,count=n()))
names(post_monkey_ALL.prelim2_lose) <- post_monkeyIDs2

post_combo_ALL2_lose<-
  post_combo2 %>%
  mutate(absent1 = map2_chr(
    actor,
    recipient,
    ~if_else(.x %in% names(post_monkey_ALL.prelim2_lose),true="TRUE",false="FALSE"))) %>%
    mutate(absent2 = map2_chr(
    actor,
    recipient,
    ~if_else(.y %in% post_monkey_ALL.prelim2_lose[[.x]]$ASSOCIATION,true="TRUE",false="FALSE"))) %>%
  filter(absent1 == "TRUE") %>%
  filter(absent2 == "TRUE") %>%
  dplyr::select(-absent1,-absent2)

post_ALL2_lose<-post_combo_ALL2_lose %>% 
  mutate(interaction = map2_int(
    actor, 
    recipient, 
    ~post_monkey_ALL.prelim2_lose %>% pluck(.x) %>% filter(ASSOCIATION==.y) %>% as.data.frame(.) %>% .[,2]))
post_ALL2_lose

post_ALL_matrix2_lose<-spread(post_ALL2_lose,recipient,interaction) %>% column_to_rownames(var="actor") %>% data.matrix()
post_ALL_matrix2_lose
```

### For stage 3
*Combining displacement, agression, and threat into one matrix (focal WINS all of these interactions)*
```{r}
post_monkeyIDs3<-as.character(unique(post_cont_3$FOCAL.ID))

post_monkey.prelim3<-lapply(post_monkeyIDs3, function(x){post_cont_3[post_cont_3[["FOCAL.ID"]] == x, ]})
head(post_monkey.prelim3)

post_monkey_ALL.prelim3<-
  post_monkey.prelim3 %>%
  purrr::map(~filter(.,BEHAVIOUR %in% c("A+","A-","MP+", "TH+","TH-"), CONFLICT.OUTCOME=="1")) %>% 
  purrr::map(~group_by(.,ASSOCIATION)) %>%
  purrr::map(~summarize(.,count=n()))
names(post_monkey_ALL.prelim3) <- post_monkeyIDs3

post_monkeylist3<-list(actor=post_monkeyIDs3,recipient=post_monkeyIDs3) #create list of all possible actors/recipients
post_filt3 <- function(x, y) {x == y} #create function to filter out same-monkey pairs ("FZ grooms FZ")
post_combo3 <- post_monkeylist3 %>% cross_df(.,.filter=post_filt3) #get the filtered combined list as a dataframe

post_combo_ALL3<-
  post_combo3 %>%
  mutate(absent1 = map2_chr(
    actor,
    recipient,
    ~if_else(.x %in% names(post_monkey_ALL.prelim3),true="TRUE",false="FALSE"))) %>%
    mutate(absent2 = map2_chr(
    actor,
    recipient,
    ~if_else(.y %in% post_monkey_ALL.prelim3[[.x]]$ASSOCIATION,true="TRUE",false="FALSE"))) %>%
  filter(absent1 == "TRUE") %>%
  filter(absent2 == "TRUE") %>%
  dplyr::select(-absent1,-absent2)

post_ALL3<-post_combo_ALL3 %>% 
  mutate(interaction = map2_int(
    actor, 
    recipient, 
    ~post_monkey_ALL.prelim3 %>% pluck(.x) %>% filter(ASSOCIATION==.y) %>% as.data.frame(.) %>% .[,2]))
post_ALL3

post_ALL_matrix3<-spread(post_ALL3,recipient,interaction) %>% column_to_rownames(var="actor") %>% data.matrix()
post_ALL_matrix3
```

*Combining displacement, agression, and threat into one matrix (focal LOSES all of these interactions)*
```{r}
post_monkey_ALL.prelim3_lose<-
  post_monkey.prelim1 %>%
  purrr::map(~filter(.,BEHAVIOUR %in% c("A+","A-","MP+", "TH+","TH-"), CONFLICT.OUTCOME=="2")) %>% 
  purrr::map(~group_by(.,ASSOCIATION)) %>%
  purrr::map(~summarize(.,count=n()))
names(post_monkey_ALL.prelim3_lose) <- post_monkeyIDs3

post_combo_ALL3_lose<-
  post_combo3 %>%
  mutate(absent1 = map2_chr(
    actor,
    recipient,
    ~if_else(.x %in% names(post_monkey_ALL.prelim3_lose),true="TRUE",false="FALSE"))) %>%
    mutate(absent2 = map2_chr(
    actor,
    recipient,
    ~if_else(.y %in% post_monkey_ALL.prelim3_lose[[.x]]$ASSOCIATION,true="TRUE",false="FALSE"))) %>%
  filter(absent1 == "TRUE") %>%
  filter(absent2 == "TRUE") %>%
  dplyr::select(-absent1,-absent2)

post_ALL3_lose<-post_combo_ALL3_lose %>% 
  mutate(interaction = map2_int(
    actor, 
    recipient, 
    ~post_monkey_ALL.prelim3_lose %>% pluck(.x) %>% filter(ASSOCIATION==.y) %>% as.data.frame(.) %>% .[,2]))
post_ALL3_lose

post_ALL_matrix3_lose<-spread(post_ALL3_lose,recipient,interaction) %>% column_to_rownames(var="actor") %>% data.matrix()
post_ALL_matrix3_lose
```

RESULTS: Based on all agonistic behaviors, the dominance hierarchy in the troop appears stable. There is no evidence suggesting a major change in dominance order from the pre-release stage. There is also no evidence suggesting a wild male took over as the highest ranking individual. Pops remains the highest ranking male and Blue remains the highest ranking female throughout all stages of the post-release period. 

## Mortality by Month

*Creating a data frame for mortality by month*
```{r}
month<- c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sept","Oct","Nov","Dec")
confirmed_death<- c(0,0,0,0,0,1,0,3,2,0,1,1)
assumed_death<- c(0,0,0,2,0,0,0,2,0,2,1,1)

mortality_cal<- data.frame(month,confirmed_death,assumed_death)
mortality_cal<- mortality_cal %>%
  rowwise() %>%
  mutate(total = sum(c_across(confirmed_death:assumed_death))) #including a column at the end with total confirmed and assumed deaths per month

mortality_cal2<- curl("https://raw.githubusercontent.com/langley1/LWTdata2016/main/Mortality%20Cal.csv") #created my own df in excel
mortality_cal2<- read.csv(mortality_cal2, header = T, na.strings=c(""," ")) %>%
  drop_na(Type.Death)
```

*Creating a plot that shows mortality in each month*
```{r}
library(ggplot2)
#this version uses the dataframe that I made by hand in r, was having trouble stacking the assumed and confirmed deaths
mortalitycal_plot<- ggplot(data=mortality_cal, aes(x=month, y=, fill=confirmed_death)) +
  geom_bar(stat="identity") +
  scale_x_discrete(limits=mortality_cal$month) #this stops ggplot from ordering my months alphabetically 
mortalitycal_plot

#this version uses the dataframe I made using an excel datasheet 
mortalitycal_plot<- ggplot(data=mortality_cal2, aes(x=Month, y=Death, fill=Type.Death)) +
  geom_bar(stat="identity", width= 0.9) +
  scale_x_discrete(limits=mortality_cal2$Month) + #this stops ggplot from ordering my months alphabetically 
  labs(x= "Month",y="Number of Deaths") +
  scale_fill_discrete(name = "Type of Death", labels = c("Assumed Dead", "Confirmed Dead", "NA")) +
  scale_fill_brewer(palette = "Reds") + theme_minimal()
mortalitycal_plot #this looks good but the months are unevenly spaced, possibly due to longer/shorter months??

ggsave("Month Mortality Plot.pdf", width = 5, height= 4, last_plot())

#trying code I found online to fix the uneven spacing for months
niceFormatting <- format(mortality_cal2$Month, "%b") # %b is supposed to be for noting abbreviated months but I get an error with this 
MonthFactor <- factor(niceFormatting, levels = niceFormatting)

#also tried turning month column in characters to see if that helps 
mortality_cal2 %>% mutate_if(is.factor, as.character) -> mortality_cal2
str(mortality_cal2)
```

## Exploring Position in Canopy

### Bar Plots
```{r}
# Looking at position in canopy grouped by sex (M/F)
PIC_plot<- post_focals %>% 
  drop_na(POSITION.IN.CANOPY) %>% #removing all NAs in this column so they don't show up on graph
  mutate(POSITION.IN.CANOPY = fct_relevel(POSITION.IN.CANOPY, "G", "LC1", "LC2", "MC1", "MC2", "TC1", "TC2", "TC3", "MMS", "NS1")) %>% #This is to re-order the x-axis so that I can have MMS and NS at the end rather than right in the middle 
    ggplot( aes(POSITION.IN.CANOPY, group = SEX)) +
    geom_bar(aes(y = ..prop..), stat="count") + 
    scale_y_continuous(labels=scales::percent) +
    theme(axis.text.x = element_text(angle = 45, hjust =1)) +
    ylab("Percentage Recorded in Canopy Position") +
    xlab("Position in Canopy") +
    facet_grid(~SEX)
PIC_plot

# Looking at position in canopy grouped by age (A/SA/J)
age_PIC_plot<- post_focals %>% 
  drop_na(POSITION.IN.CANOPY) %>% #removing all NAs in this column so they don't show up on graph
  filter(AGE != "I") %>% #removing infants
  mutate(POSITION.IN.CANOPY = fct_relevel(POSITION.IN.CANOPY, "G", "LC1", "LC2", "MC1", "MC2", "TC1", "TC2", "TC3", "MMS", "NS1")) %>% #This is to re-order the x-axis so that I can have MMS and NS at the end rather than right in the middle 
    ggplot( aes(POSITION.IN.CANOPY, group = AGE)) +
    geom_bar(aes(y = ..prop..), stat="count") + 
    theme(axis.text.x = element_text(angle = 45, hjust =1)) +
    scale_y_continuous(labels=scales::percent) +
    ylab("Percentage Recorded in Canopy Position") +
    xlab("Position in Canopy") +
    facet_grid(~AGE)
age_PIC_plot

# Looking at position in canopy of females only, grouped by age (I took out infants)
fems_PIC_plot<- post_focals %>% 
  drop_na(POSITION.IN.CANOPY) %>% #removing all NAs in this column so they don't show up on graph
  filter(SEX == "F", AGE %in% c("A","J")) %>% #filtering out females and adults/juveniles (no infants)
  mutate(POSITION.IN.CANOPY = fct_relevel(POSITION.IN.CANOPY, "G", "LC1", "LC2", "MC1", "MC2", "TC1", "TC2", "TC3", "MMS", "NS1")) %>% #This is to re-order the x-axis so that I can have MMS and NS at the end rather than right in the middle
  ggplot( aes(POSITION.IN.CANOPY, group = AGE)) +
  geom_bar(aes(y = ..prop..), stat="count") + 
  scale_y_continuous(labels=scales::percent) +
  scale_fill_manual(values = c("G"= "black","LC1"= "orange","LC2"= "blue","MC1"= "black","MC2"= "orange","TC1"= "blue","TC2" ="black","TC3"= "orange","MMS"= "blue","NS1"= "black")) + #This color code DOESN'T WORK
  facet_grid(~AGE) +
  ylab("Percentage Recorded in Canopy Position") +
  xlab("Position in Canopy")
fems_PIC_plot

#Pops, Jack, Mango (adult/SA males) from March-May because Jack dies in June
Males_canopy_test<- post_focals %>% filter(FOCAL.ID %in% c("PO","JA","MG"), MONTH %in% c("3","4","5")) %>% drop_na(POSITION.IN.CANOPY) %>% mutate(POSITION.IN.CANOPY = fct_relevel(POSITION.IN.CANOPY, "G", "LC1", "LC2", "MC1", "MC2", "TC1", "TC2", "TC3", "MMS", "NS1"))
str(Males_canopy_test)                                                                      
#This one looks strange by the x-axis
ggplot(Males_canopy_test, aes(POSITION.IN.CANOPY, fill = factor(FOCAL.ID))) +
  geom_bar() +
  geom_bar(aes(stat="count")) + 
  scale_y_continuous(labels=scales::percent) +
  ylab("prop")

#Super high percentages on y-axis
ggplot(Males_canopy_test, aes(POSITION.IN.CANOPY, fill = factor(FOCAL.ID))) +
  geom_bar(position = position_dodge2(preserve = "single")) +
  geom_bar(aes(y = (..count..)/sum(..count..))) + 
  scale_y_continuous(labels=scales::percent) +
  ylab("prop")

#aes(y = ..prop.., group = 1), stat="count", 

par(mfrow=c(2,2))
PIC_plot
age_PIC_plot
fems_PIC_plot
```

RESULTS: Overall, both males and females were most frequently positioned on the ground during post-release monitoring (Figure PIC_plot). They were also located in the lower and middle tree canopies more often than top canopies (Figure PIC_plot). Out of the three canopy levels (LC,MC,TC), all individuals were located in the lowest height category (1) most often, remaining 5m or less above the ground, and were rarely seen higher up in the canopy (2,3).  

RESULTS: All age groups of both sexes were most frequently positioned on the ground and in lower and middle tree canopies less than 5m above the ground (Figure age_PIC_plot). Out of the three canopy levels, all individuals across age groups were positioned in the top canopy least often and rarely moved up higher than 5m above the ground in any canopy level (Figure age_PIC_plot).

## Density Plots
```{r}
xaxislabels<- c("Ground", "LC <5m", "LC 5-10m", "MC <5m", "MC 5-10m", "TC <5m", "TC 5-10m", "TC 10-20m", "Manmade", "Natural <5m") #creating new labels for the x axis so that I can add these into the density plots

post_focals_colrenamed <- post_focals %>% rename_at('FOCAL.ID', ~ 'ID') #I was struggling with changing the legend title so I created a new df here "post_focals_colrenamed" and changed the FOCAL.ID column title to just "ID" so now that will be the legend title in our density plot

#Density plot with adult females only
fems_denPIC_plot<- ggplot((post_focals %>% filter(SEX == "F", AGE == "A")) %>%
  mutate(POSITION.IN.CANOPY = fct_relevel(POSITION.IN.CANOPY, "G", "LC1", "LC2", "MC1", "MC2", "TC1", "TC2", "TC3", "MMS", "NS1")) %>%
  drop_na(POSITION.IN.CANOPY), aes(x = POSITION.IN.CANOPY)) +  
  geom_density(aes(group = FOCAL.ID, 
                   colour = FOCAL.ID, 
                   fill = FOCAL.ID),
               alpha = 0.2) +
  xlab("Position in Canopy") +
  ylab("Density") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
fems_denPIC_plot
ggsave("Fems PICDensity Plot.pdf", width= 7, height= 4, last_plot())

post_focals %>% filter(POSITION.IN.CANOPY == "Mc1")

#density plot with adult males only: CAN'T Figure out how to change legend name
males_denPIC_plot<- ggplot((post_focals %>% filter(SEX == "M",AGE == "A",FOCAL.ID != "PA") %>% #Taking out Patches because he only had 2 focals
  mutate(POSITION.IN.CANOPY = fct_relevel(POSITION.IN.CANOPY, "G", "LC1", "LC2", "MC1", "MC2", "TC1", "TC2", "TC3", "MMS", "NS1")) %>%                         
  drop_na(POSITION.IN.CANOPY)), aes(x = POSITION.IN.CANOPY)) +  
  geom_density(aes(group = FOCAL.ID, 
                   colour = FOCAL.ID, 
                   fill = FOCAL.ID),
               show.legend = T,
               alpha = 0.2) +
  xlab("Position in Canopy") +
  ylab("Density") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
males_denPIC_plot
ggsave("Males PICDensity Plot.pdf", width = 7, height = 4, last_plot())

#Density plot with subadult and juveniles (males/fems)
age_denPIC_plot<- ggplot((post_focals %>% filter(AGE %in% c("SA","J"), FOCAL.ID != "RE") %>% #Taking out Red because she only had 2 focal observations
  mutate(POSITION.IN.CANOPY = fct_relevel(POSITION.IN.CANOPY, "G", "LC1", "LC2", "MC1", "MC2", "TC1", "TC2", "TC3", "MMS", "NS1")) %>%
  drop_na(POSITION.IN.CANOPY)), aes(x = POSITION.IN.CANOPY)) +  
  geom_density(aes(group = FOCAL.ID, 
                   colour = FOCAL.ID, 
                   fill = FOCAL.ID),
               alpha = 0.2) +
  xlab("Position in Canopy") +
  ylab("Density") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
age_denPIC_plot
ggsave("SA&J PICDensity Plot.pdf", width = 7, height = 4, last_plot())

par(mfrow=c(3,1))
fems_denPIC_plot
males_denPIC_plot
age_denPIC_plot
ggsave("Full PICDensity Plot.pdf", last_plot())
```

METHODS: Density plots were created in ggplot to show the probability density of each indiviudals position in the canopy throughout the post-release stage.

RESULTS: Cicero and Homer, the two wild males that joined the troop for some time, were positioned in the top canopy more than all other adult males (Figure males_denPIC_plot). Cicero was positioned higher up in the top canopy (5-10m off the ground) more often than all other adult males and was positioned on the ground less than all other adult males (Figure). 

*GLMM For PIC*
```{r}
#Filter out all individuals we don't want for this glmm
post_focals_glmm<- post_focals %>%
  filter(AGE != "I", !FOCAL.ID %in% c("RE","PA","SK","CI","HO","ZI"), !POSITION.IN.CANOPY %in% c("MMS","NS1")) %>%
  droplevels() %>%
  rename(sex = SEX, #renaming these columns 
         age = AGE,
         PIC = POSITION.IN.CANOPY,
         ID = FOCAL.ID) %>%
  drop_na(PIC) %>%
  mutate(rank =
           case_when(ID == "PO"~ as.numeric(1),
                     ID == "BL"~ as.numeric(2),
                     ID == "AM"~ as.numeric(3),
                     ID == "AL"~ as.numeric(4),
                     ID == "TO"~ as.numeric(5),
                     ID == "AU"~ as.numeric(6),
                     ID == "BO"~ as.numeric(7),
                     ID == "JA"~ as.numeric(8),
                     ID == "MG"~ as.numeric(9),
                     ID == "ED"~ as.numeric(10),
                     ID == "MA"~ as.numeric(11),
                     ID == "BM"~ as.numeric(12),
                     ID == "NE"~ as.numeric(13),
                     ID == "KO"~ as.numeric(14),
                     ID == "TI"~ as.numeric(15)))

post_focals_glmm<- as.data.frame(unclass(post_focals_glmm)) #turning all character columns into factors
post_focals_glmm$rank<- as.factor(post_focals_glmm$rank) #turning this numeric column into factor

#Glmer (doesn't work)
m1 <- glmer(
  PIC ~ age + sex + (1 | ID), 
  data = post_focals_glmm
)

#Mlogit (doesnt work)
library(mlogit)
PIC.l<- mlogit.data(post_focals_glmm, varying = NULL, choice = "PIC", shape = "wide", id.var = "ID")
m <- mlogit(PIC ~ age + sex | ID, data = PIC.l)
summary(m)
```

## Using the Ordinal package- this works?? but not sure
```{r}
library(ordinal)
library(lsmeans)
post_focals_glmm$PIC <- ordered(post_focals_glmm$PIC)
str(post_focals_glmm)

fm1 <- clm(PIC ~ rank, data=post_focals_glmm, link= "logit")
summary(fm1)
exp(coef(fm1))

fm2<- clmm(PIC~ sex + age + (1|ID), data = post_focals_glmm, link="probit", threshold = "equidistant")
summary(fm2)
lsmeans(fm2, pairwise~sex, adjust="tukey", mode = "mean.class")


clmm2(PIC ~ sex + age, random = ID, data = post_focals_glmm, nAGQ= 10)
```

## Trying using the Mixor Package - this does NOT seem to work
```{r}
library(mixor)
post_focals_mixor<- post_focals_glmm %>%
  mutate(Pic_num = 
           case_when(PIC == "G"~ as.numeric(1),
                     PIC == "LC1"~as.numeric(2),
                     PIC == "LC2"~as.numeric(3),
                     PIC == "MC1"~as.numeric(4),
                     PIC == "MC2"~as.numeric(5),
                     PIC == "TC1"~as.numeric(6),
                     PIC == "TC2"~as.numeric(7),
                     PIC == "TC3"~as.numeric(8))) %>%
  mutate(sex_num = 
           case_when(sex == "M"~ as.numeric(1),
                     sex == "F"~ as.numeric(2)))
head(post_focals_mixor)


SP<- data("SmokingPrevention")
head(SmokingPrevention)
post_focals_glmm<-post_focals_glmm[order(post_focals_glmm$ID),]
mixortest<- mixor(Pic_num ~ sex, data = post_focals_mixor, id= ID, link = "logit")
mixortest
```

# Vigilance Counts

### Filtering out each individual from the post-focals dataset
```{r}
Pops_post<- post_focals %>% filter(FOCAL.ID == "PO")
Jack_post<- post_focals %>% filter(FOCAL.ID == "JA")
Blue_post<- post_focals %>% filter(FOCAL.ID == "BL")
Amy_post<- post_focals %>% filter(FOCAL.ID == "AM")
Alex_post<- post_focals %>% filter(FOCAL.ID == "AL")
Bgm_post<- post_focals %>% filter(FOCAL.ID == "BM")
Nev_post<- post_focals %>% filter(FOCAL.ID == "NE")
Mango_post<- post_focals %>% filter(FOCAL.ID == "MG")
Eddy_post<- post_focals %>% filter(FOCAL.ID == "ED")
May_post<- post_focals %>% filter(FOCAL.ID == "MA")
Kovu_post<- post_focals %>% filter(FOCAL.ID == "KO")
Tink_post<- post_focals %>% filter(FOCAL.ID == "TI")
Toni_post<- post_focals %>% filter(FOCAL.ID == "TO")
Boo_post<- post_focals %>% filter(FOCAL.ID == "BO")
Aug_post<- post_focals %>% filter(FOCAL.ID == "AU")
Cic_post<- post_focals %>% filter(FOCAL.ID == "CI")
Homer_post<- post_focals %>% filter(FOCAL.ID == "HO")
```

### Post-Release Vigilance Counts from each Individual
```{r}
Pops_vig2<- Pops_post %>% 
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% #filtering out only the vigilance behavior from this new "behavior" column created by gather()
  summarize(count=n()) #counting all the vigilance entries
Pops_vig2$prop<- Pops_vig2$count/nrow(Pops_post)
Pops_vig2$ID<- "Pops"

Jack_vig2<- Jack_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Jack_vig2$prop<- Jack_vig2$count/nrow(Jack_post)
Jack_vig2$ID<- "Jack"

Blue_vig2<- Blue_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Blue_vig2$prop<- Blue_vig2$count/nrow(Blue_post)
Blue_vig2$ID<- "Blue"

Alex_vig2<- Alex_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Alex_vig2$prop<- Alex_vig2$count/nrow(Alex_post)
Alex_vig2$ID<- "Alex"

Nev_vig2<- Nev_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Nev_vig2$prop<- Nev_vig2$count/nrow(Nev_post)
Nev_vig2$ID<- "Neville"

Aug_vig2<- Aug_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Aug_vig2$prop<- Aug_vig2$count/nrow(Aug_post)
Aug_vig2$ID<- "Aug"

Amy_vig2<- Amy_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Amy_vig2$prop<- Amy_vig2$count/nrow(Amy_post)
Amy_vig2$ID<- "Amy"

May_vig2<- May_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
May_vig2$prop<- May_vig2$count/nrow(May_post)
May_vig2$ID<- "May"

Toni_vig2<- Toni_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Toni_vig2$prop<- Toni_vig2$count/nrow(Toni_post)
Toni_vig2$ID<- "Toni"

Boo_vig2<- Boo_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Boo_vig2$prop<- Boo_vig2$count/nrow(Boo_post)
Boo_vig2$ID<- "Boo"

Bgm_vig2<- Bgm_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Bgm_vig2$prop<- Bgm_vig2$count/nrow(Bgm_post)
Bgm_vig2$ID<- "Big Mama"

Kovu_vig2<- Kovu_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Kovu_vig2$prop<- Kovu_vig2$count/nrow(Kovu_post)
Kovu_vig2$ID<- "Kovu"

Ed_vig2<- Eddy_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Ed_vig2$prop<- Ed_vig2$count/nrow(Eddy_post)
Ed_vig2$ID<- "Eddy"

Tink_vig2<- Tink_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Tink_vig2$prop<- Tink_vig2$count/nrow(Tink_post)
Tink_vig2$ID<- "Tinker"

Mango_vig2<- Mango_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Mango_vig2$prop<- Mango_vig2$count/nrow(Mango_post)
Mango_vig2$ID<- "Mango"

Cic_vig2<- Cic_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Cic_vig2$prop<- Cic_vig2$count/nrow(Cic_post)
Cic_vig2$ID<- "Cicero"

Homer_vig2<- Homer_post %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
Homer_vig2$prop<- Homer_vig2$count/nrow(Homer_post)
Homer_vig2$ID<- "Homer"
```

*Creating a vigilance dataframe*
```{r}
vig2_df_ALL<- list(Pops_vig2, Jack_vig2, Blue_vig2, Alex_vig2, Nev_vig2, Aug_vig2, Amy_vig2, May_vig2, Toni_vig2, Boo_vig2, Bgm_vig2, Kovu_vig2, Ed_vig2, Tink_vig2, Mango_vig2) #leaving out Cicero and Homer here because they're wild males
vig2_df_ALL<- Reduce(function(x, y) merge(x, y, all=TRUE), vig2_df_ALL, accumulate=FALSE) #this changes it from a "list" item to an actual data frame
str(vig2_df_ALL)

#Adding a "sex" column
vig2_df_ALL<- vig2_df_ALL %>% 
  add_column(sex = c("M","F","F","M","M","F","F","F","F","F","F","F","F","F", "M"), .after="ID")
```

*Plotting the vigilance dataframe*
```{r}
ggplot(vig2_df_ALL, aes(x = reorder(ID, -prop), y = prop), fill= sex) + #the reorder function with -prop reorders the x-axis to go from highest to lowest
  geom_bar(stat = "identity") + 
  scale_y_continuous(labels=scales::percent) + #this changes the y-axis to percents
  theme(axis.text.x = element_text(angle = 45, hjust =1)) + #turns axis labels to 45 degrees and hjust get rid of excess space
  ylab("Percent Vigilance Behavior") +
  xlab("Individual") +
  scale_fill_manual("legend", values = c("F" = "red", "M" = "blue")) #doesn't want to work
```

*Post-release Vigilance across entire troop*
```{r}
post_focals_vig<- post_focals %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>%
  group_by(behavior) %>% 
  filter(behavior == "V") %>% 
  summarize(count=n())
post_focals_vig$prop<- post_focals_vig$count/nrow(post_focals)
```

### Vigilance Dataframe Editing
```{r}
#first filtering out all of the individuals that have little or no focal data post-release
post_focals_edited<- post_focals %>%
  rename(day = DAY, hour= TIME..HOUR.) %>%
  filter(!FOCAL.ID %in% c("PA","ZI","RE","SK","HO","CI")) %>%
  droplevels()

#creating a "vigilance-only" dataframe
post_focals_vig<- post_focals_edited %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>% #combining behavior1&2
  group_by(behavior) %>% 
  filter(behavior == "V") #pulling out vigilance
```

### Rate of Vigilance for ADULT FEMALES
```{r}
#1. Create a new dataframe with adult females only
post_focals_Afems<- post_focals_edited %>%
  filter(SEX == "F", AGE == "A")

#2. create a character list of all adult female IDs
MonkeyIDs_postAfems<- as.character(unique(post_focals_Afems$FOCAL.ID))
MonkeyIDs_postAfems

# 2. Get a list of dataframes (from the updated vigilance dataframe), subsetted by adult female monkey ID
monkey.list_postAfems<-lapply(MonkeyIDs_postAfems, function(x){post_focals_vig[post_focals_vig[["FOCAL.ID"]] == x, ]})
head(monkey.list_postAfems)

#3. Create new list of tibbles to look at vigilance counts per hour 
monkey.list_post_vigAfems<-
  monkey.list_postAfems %>%
  purrr::map(~group_by(.,day,hour)) %>% #grouping by day&hour so that I get a vigilance count for each unique day-hour combination per individual 
  purrr::map(~summarize(.,count=n())) #counting up vigilance
names(monkey.list_post_vigAfems)<- MonkeyIDs_postAfems
head(monkey.list_post_vigAfems)

# Trying to 
monkey.list_post_vigAfems<- monkey.list_post_vigAfems %>%
  #purrr::map(~mutate(.,mean= ((summarize(sum(count)))/nrow(.))))
  
monkey.list_post_vigAfems$TI


#4. Combining all the tibbles into one
monkey.list_post_vigAfems<- monkey.list_post_vigAfems %>% 
  purrr::reduce(dplyr::full_join) %>% #using full_join since all columns are the same across tibbles
  mutate(release = "post") #creating a new column called "release"
monkey.list_post_vigAfems
mean(monkey.list_post_vigAfems$count) #7.16
```

*Pre/Post Adult Female Vigilance Tibble*
```{r}
monkey.list_vigAfems_FULL<- full_join(monkey.list_post_vigAfems, monkey.list_pre_vigAfems) #joining the two vigilance tibbles together
```

### Testing for Adult Female Vigilance Normality
```{r}
#calculating the difference between release stages to test for normality
x <- with(monkey.list_vigAfems_FULL, 
        count[release == "post"] - count[release == "pre"])
# Shapiro-Wilk normality test for the differences
shapiro.test(x)

#Looking at density plots and qqplots to check for normality
ggdensity(monkey.list_vigAfems_FULL$count)
ggqqplot(monkey.list_vigAfems_FULL$count)

#Plotting pre and post vigilance rates 
ggplot(monkey.list_vigAfems_FULL, aes(x=release, y=count, color=release)) +
  geom_boxplot(outlier.color = "black", notch = TRUE) +
  scale_x_discrete(limits=c("pre", "post")) +
  labs(x= "Release Stage", y= "Mean hourly rate of vigilance")
  

#Running log10 transformations to see if that changes distribution
log<- log10(monkey.list_vigAfems_FULL$count)
shapiro.test(log)
ggdensity(log)
ggqqplot(log)
```

METHODS: To test for normality, Shapiro-Wilk tests were performed on hourly vigilance rate data for each age/sex category. Where Shapiro-Wilk tests revealed non-normal distributions, Log10 transformations were conducted and normality was reassessed. When Log10 transformations also showed non-normal distribution, non-parametric tests were run on the un-logged variables. 

The Log10 transformations for 1) adult female, 2) subadult & juvenile, and 3) Pops hourly vigilance rates show non-normal distribution.

### Wilcoxon Test for Adult Fems
```{r}
#Doing a unpaired two-sample Wilcoxon test because I get an error when I do it paired
WT_vigAfems<- wilcox.test(count ~ release, data = monkey.list_vigAfems_FULL, exact = TRUE)
WT_vigAfems

#add in ID names as row names
#When paired = TRUE, I get an error that x and y need to be the same length
```

RESULTS: There is a significant difference in mean hourly vigilance rates of adult females pre- and post-release. 

### Rate of Vigilance for Subadults and Juveniles
```{r}
#1. Create a new dataframe with SA & juvs only
post_focals_young<- post_focals_edited %>%
  filter(AGE %in% c("SA","J"))

#2. create a character list of all SA & juvs
MonkeyIDs_postyoung<- as.character(unique(post_focals_young$FOCAL.ID))
MonkeyIDs_postyoung

# 2. Get a list of dataframes (from the updated vigilance dataframe), subsetted by monkey ID
monkey.list_postyoung<-lapply(MonkeyIDs_postyoung, function(x){post_focals_vig[post_focals_vig[["FOCAL.ID"]] == x, ]})
head(monkey.list_postyoung)

#3. Create new list of tibbles to look at vigilance counts per hour 
monkey.list_post_vigyoung<-
  monkey.list_postyoung %>%
  purrr::map(~group_by(.,day,hour)) %>% #grouping by day&hour so that I get a vigilance count for each unique day-hour combination per individual 
  purrr::map(~summarize(.,count=n())) #counting up vigilance 
head(monkey.list_post_vigyoung)

#4. Combining all the tibbles into one
monkey.list_post_vigyoung<- monkey.list_post_vigyoung %>% 
  purrr::reduce(dplyr::full_join) %>% #using full_join since all columns are the same across tibbles
  mutate(release = "post") #creating a new column called "release"
monkey.list_post_vigyoung
mean(monkey.list_post_vigyoung$count) #6.59
```

*Pre/Post Subadult & Juvenile Vigilance Tibble*
```{r}
monkey.list_vigyoung_FULL<- full_join(monkey.list_post_vigyoung, monkey.list_pre_vigyoung) #joining the two vigilance tibbles together
monkey.list_vigyoung_FULL
```

### Testing for Subadult & Juvenile Vigilance Normality
```{r}
#calculating the difference between release stages to test for normality
x2 <- with(monkey.list_vigyoung_FULL, 
        count[release == "post"] - count[release == "pre"])
# Shapiro-Wilk normality test for the differences
shapiro.test(x2)

#Looking at density plots and qqplots to check for normality
ggdensity(monkey.list_vigyoung_FULL$count)
ggqqplot(monkey.list_vigyoung_FULL$count)

#Plotting pre and post vigilance rates 
ggplot(monkey.list_vigyoung_FULL, aes(x=release, y=count, color=release)) +
  geom_boxplot(outlier.color = "black", notch = TRUE) +
  scale_x_discrete(limits=c("pre", "post")) +
  labs(x= "Release Stage", y= "Average rate of vigilance")

#Running log10 transformations to see if that changes distribution
log2<- log10(monkey.list_vigyoung_FULL$count)
shapiro.test(log2)
ggdensity(log2)
ggqqplot(log2)
```

### Wilcoxon Test for Subs/Juvs
```{r}
#Doing a unpaired two-sample Wilcoxon test because I get an error when I do it paired
WT_vigyoung<- wilcox.test(count ~ release, data = monkey.list_vigyoung_FULL, exact = FALSE)
WT_vigyoung

#When paired = TRUE, I get an error that x and y need to be the same length
```

RESULTS: There is a significant difference in mean hourly vigilance rates of subadults and juveniles pre- and post-release. 

### Rate of Vigilance for Pops
```{r}
post_focals_vigPops<- post_focals_vig %>%
  filter(FOCAL.ID == "PO") %>%
  group_by(day,hour) %>%
  summarize(count=n()) %>%
  mutate(release = "post")
  
mean(post_focals_vigPops$count) #8.38
```

*Pre/Post Pops Vigilance Tibble*
```{r}
post_focals_vigPops_FULL<- full_join(post_focals_vigPops, pre_focals_vigPops) #joining the two vigilance tibbles together
post_focals_vigPops_FULL
```

### Testing for Pops Normality
```{r}
#calculating the difference between release stages to test for normality
x3 <- with(post_focals_vigPops_FULL, 
        count[release == "post"] - count[release == "pre"])
# Shapiro-Wilk normality test for the differences
shapiro.test(x3)
shapiro.test(post_focals_vigPops_FULL$count)

#Looking at density plots and qqplots to check for normality
ggdensity(post_focals_vigPops_FULL$count)
ggqqplot(post_focals_vigPops_FULL$count)

#Plotting pre and post vigilance rates 
ggplot(post_focals_vigPops_FULL, aes(x=release, y=count, color=release)) +
  geom_boxplot(outlier.color = "black", notch = TRUE) +
  scale_x_discrete(limits=c("pre", "post")) +
  labs(x= "Release Stage", y= "Average rate of vigilance")

#Running log10 transformations to see if that changes distribution
log3<- log10(post_focals_vigPops_FULL$count)
shapiro.test(log3)
ggdensity(log3)
ggqqplot(log3)
```

### Wilcoxon Test
```{r}
#Doing a unpaired two-sample Wilcoxon test because I get an error when I do it paired
WT_vigPops<- wilcox.test(count ~ release, data = post_focals_vigPops_FULL, exact = FALSE)
WT_vigPops

#When paired = TRUE, I get an error that x and y need to be the same length
```

RESULTS: There is a significant difference in Pop's mean hourly vigilance rates pre- and post-release. 

```{r}
shapiro.test(monkey.list_pre_vigAfems$count)
histogram(monkey.list_pre_vigAfems$count)


```

## Social Network Code:
```{r}
# 1. Create a character vector of all the focal IDs in your dataset:
pre_sn_closeIDs<-as.character(unique(pre_socnet_close$Focal.ID))

# 2. Get a list of dataframes, subsetted by monkey ID:
pre_sn_monkeylist<-lapply(pre_sn_closeIDs, function(x){pre_socnet_close[pre_socnet_close[["Focal.ID"]] == x, ]})
head(pre_sn_monkeylist) #this will load the first 6 lists, take a look at them and see that each is for an individual monkey

# 3. Group each by focal/associate, and count how many times they are observed close together:
pre_sn_grouped<-
  pre_sn_monkeylist %>%
  purrr::map(~group_by(.,Association)) %>%
  purrr::map(~summarize(.,count=n())) 
names(pre_sn_grouped) <- pre_sn_closeIDs #this will give each grouped list the name of the Focal ID

# 4. Set up your pairwise combinations of interacting monkeys:
pre_sn_monkeycombos<-list(focal=pre_sn_closeIDs, associate=pre_sn_closeIDs) #create list of all possible focals/associates
pre_sn_filt<- function(x, y) {x == y} #create function to filter out same-monkey pairs ("PO is close to PO")
pre_sn_combo<- pre_sn_monkeycombos %>% cross_df(.,.filter=pre_sn_filt) #get the filtered combined list as a dataframe
head(pre_sn_combo)

pre_sn_combo2<-
  pre_sn_combo %>%
  mutate(absent1 = map2_chr(
    focal,
    associate,
    ~if_else(.x %in% names(pre_sn_grouped),true="TRUE",false="FALSE"))) %>%
    mutate(absent2 = map2_chr(
    focal,
    associate,
    ~if_else(.y %in% pre_sn_grouped[[.x]]$Association,true="TRUE",false="FALSE"))) %>%
  filter(absent1 == "TRUE") %>%
  filter(absent2 == "TRUE") %>%
  dplyr::select(-absent1,-absent2)

pre_sn_combo3<- pre_sn_combo2 %>% 
  mutate(proximity = map2_int(
    focal, 
    associate, 
    ~pre_sn_grouped %>% pluck(.x) %>% filter(Association==.y) %>% as.data.frame(.) %>% .[,2]))
pre_sn_combo3

pre_sn_matrix<-spread(pre_sn_combo3,associate,proximity) %>% column_to_rownames(var="focal") %>% data.matrix()
pre_sn_matrix
```

## Activity Budgets
### Behavior Categories
```{r}
post_focals_budget<- post_focals %>%
  filter(!FOCAL.ID %in% c("CI","HO","PA")) %>%
  gather("Obs", "behavior", 20:21, na.rm = T) %>% #gathering the two behavior columns
  filter(!behavior %in% c("ED","TH","VL")) %>% #removing these from the behavior column becuase they're mistakes
  mutate(behavior.category = #creating new column for behavior categories
           case_when(behavior %in% c("G+","G-","PR-","PR+","C","CL","N","SU","PL","MA","MO") ~ as.character("Social"),
                     behavior %in% c("F","FE","FO") ~ as.character("Feeding"),
                     behavior %in% c("L","R") ~ as.character("Activity"),
                     behavior %in% c("V","PA") ~ as.character("Predator"),
                     behavior %in% c("A+","A-","TH+","TH-","MP+","MP-") ~ as.character("Dominance"),
                     behavior %in% c("YA","SC","SG","SM","PC") ~ as.character("Stress"),
                     behavior %in% c("PH","AH")~ as.character("Human"),
                     behavior %in% c("O","OS","oS")~ as.character("Other"))) %>%
  rename(focal.reference = FOCAL.REFERENCE.CODE)
unique(post_focals_budget$behavior.category)
```

### Mean Activity Budget Per Focal
```{r}
#Pops
Pops_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "PO") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Pops_budget2<- Pops_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Pops_budget2$focal.reference))))
Pops_budget2$total<- NULL

#Blue
Blue_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "BL") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Blue_budget2<- Blue_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Blue_budget2$focal.reference))))
Blue_budget2$total<- NULL

#Amy
Amy_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "AM") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Amy_budget2<- Amy_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Amy_budget2$focal.reference))))
Amy_budget2$total<- NULL

#Alex
Alex_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "AL") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Alex_budget2<- Alex_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Alex_budget2$focal.reference))))
Alex_budget2$total<- NULL

#Boo
Boo_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "BO") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Boo_budget2<- Boo_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Boo_budget2$focal.reference))))
Boo_budget2$total<- NULL

#Big Mama
Bgm_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "BM") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Bgm_budget2<- Bgm_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Bgm_budget2$focal.reference))))
Bgm_budget2$total<- NULL

#Augustine
Aug_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "AU") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Aug_budget2<- Aug_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Aug_budget2$focal.reference))))
Aug_budget2$total<- NULL

#Eddy
Ed_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "ED") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Ed_budget2<- Ed_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Ed_budget2$focal.reference))))
Ed_budget2$total<- NULL

#Jack
Jack_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "JA") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Jack_budget2<- Jack_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Jack_budget2$focal.reference))))
Jack_budget2$total<- NULL

#Tinker
Tink_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "TI") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Tink_budget2<- Tink_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Tink_budget2$focal.reference))))
Tink_budget2$total<- NULL

#Kovu
Kovu_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "KO") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Kovu_budget2<- Kovu_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Kovu_budget2$focal.reference))))
Kovu_budget2$total<- NULL

#Mango
Mango_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "KO") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Mango_budget2<- Mango_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Mango_budget2$focal.reference))))
Mango_budget2$total<- NULL

#Neville
Nev_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "NE") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Nev_budget2<- Nev_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Nev_budget2$focal.reference))))
Nev_budget2$total<- NULL

#Toni
Toni_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "TO") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Toni_budget2<- Toni_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Toni_budget2$focal.reference))))
Toni_budget2$total<- NULL

#May
May_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "MA") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

May_budget2<- May_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(May_budget2$focal.reference))))
May_budget2$total<- NULL

#Zip
Zip_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "ZI") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Zip_budget2<- Zip_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Zip_budget2$focal.reference))))
Zip_budget2$total<- NULL

#Red
Red_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "RE") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Red_budget2<- Red_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Red_budget2$focal.reference))))
Red_budget2$total<- NULL

#Skittles
Sk_budget2<- post_focals_budget %>%
  filter(FOCAL.ID == "SK") %>%
  group_by(focal.reference,behavior.category) %>%
  summarize(count=n())

Sk_budget2<- Sk_budget2 %>%
  group_by(behavior.category) %>%
  summarize(total= sum(count)) %>%
  mutate(Mean = (total/(n_distinct(Sk_budget2$focal.reference))))
Sk_budget2$total<- NULL
```

*Troop Mean Activity Budgets*
```{r}
post_fullbudget<- Pops_budget2 %>%
  full_join(Blue_budget2,by= "behavior.category") %>%
  full_join(Amy_budget2,by= "behavior.category") %>%
  full_join(Alex_budget2,by= "behavior.category") %>%
  full_join(Boo_budget2,by= "behavior.category") %>%
  full_join(Bgm_budget2,by= "behavior.category") %>%
  full_join(Aug_budget2,by= "behavior.category") %>%
  full_join(Ed_budget2,by= "behavior.category") %>%
  full_join(Jack_budget2,by= "behavior.category") %>%
  full_join(Tink_budget2,by= "behavior.category") %>%
  full_join(Kovu_budget2,by= "behavior.category") %>%
  full_join(Mango_budget2,by= "behavior.category") %>%
  full_join(May_budget2,by= "behavior.category") %>%
  full_join(Toni_budget2,by= "behavior.category") %>%
  full_join(Nev_budget2,by= "behavior.category") %>%
  full_join(Zip_budget2,by= "behavior.category") %>%
  full_join(Red_budget2,by= "behavior.category") %>%
  full_join(Sk_budget2,by= "behavior.category") %>%
  rowwise() %>% #this allows us to work with row-wise dataframe where we want to look at each row individually
  mutate(TroopMean = ((sum(c_across(2:19),na.rm=T))/19), #adding up all the means per category and dividing by 19 monkeys to get average
        release= "post") #adding column to identify pre-release

post_fullbudget<- post_fullbudget[,c("behavior.category","TroopMean","release")] #these are the only columns I want to look at now
post_fullbudget
```

```{r}
combined_budget_table<- bind_rows(pre_fullbudget, post_fullbudget)
combined_budget_table

full_budgetplot<- ggplot(data=combined_budget_table, aes(x=behavior.category, y=TroopMean, fill=release)) +
  geom_bar(position="dodge", stat="identity") +
  xlab("Behavior Category") +
  ylab("Mean Behavior Count")
full_budgetplot
```

#Counting the number of days of data collection post-release
```{r}
days<- post_focals %>%
  distinct(DAY, MONTH, YEAR, .keep_all = T)
days #92

#Pre-release
days2<- pre_focals %>%
  distinct(day, MONTH, YEAR, .keep_all = T)
days2 #200

post_focals %>%
  distinct(MONTH, .keep_all = T)
```

#Social Proximity Code: Dyadic matrices of close proximity

```{r}
post_socnet<- curl("https://raw.githubusercontent.com/nickmikulski/Spring2021/main/Post-release_Social%20Proximity_CSV.csv")
post_socnet<- read.csv(post_socnet, header = T, na.strings=c(""," ","NA"))
#head(post_socnet)
#str(post_socnet)

post_socnet_close<- post_socnet %>% #creating a new dataframe called post_socnet_close using data from the original post_socnet dataframe
  filter(Focal.ID != c("BT"), #this code REMOVES all data that has Batman as the focal ID (BT is wild male from prerelease)
         Association != c("BT"), #this code REMOVES all data that has Batman in association column
         Proximity.Code %in% c("1","2") #this code only keeps proximity codes 1,2 (excluding 3,4) because we are focusing on closer proximity
  ) 
#head(post_socnet_close)
```

```{r}
#library(purrr)
# 1. Create a character vector of all the focal IDs in dataset:
post_sn_IDs<-sort(as.character(unique(post_socnet_close$Focal.ID)))
#post_sn_IDs

# 2. Get a list of dataframes, subsetted by monkey ID:
post_sn_monkeylist<-lapply(post_sn_IDs, function(x){post_socnet_close[post_socnet_close[["Focal.ID"]] == x, ]})
# The line above is a little bit confusing. It is creating a separate dataframe for each individual based on their focal id
#head(post_sn_monkeylist)

# 3. Group each by focal/associate, and count how many times they are observed close together:
post_sn_grouped<-
  post_sn_monkeylist %>%
  purrr::map(~group_by(.,Association)) %>%
  purrr::map(~summarize(.,count=n())) 
post_sn_grouped

names(post_sn_grouped) <- post_sn_IDs #this gives each grouped list the name of the Focal ID
#post_sn_grouped

# 4. Set up pairwise combinations of interacting monkeys:
post_sn_monkeycombos<-list(focal=post_sn_IDs, associate=post_sn_IDs) #create list of all possible focals/associates
post_sn_filtf<- function(x, y) {x == y} #create function to filter out same-monkey pairs ("PO is close to PO")
post_sn_combo<- post_sn_monkeycombos %>% cross_df(.,.filter=post_sn_filtf) #get the filtered combined list as a dataframe
#post_sn_combo
```

```{r}
# 5. Create new dataframes with specific criteria
post_sn_combo2<-
  post_sn_combo %>%
  mutate(absent1 = map2_chr( #new column called "absent1"
    focal,
    associate,
    ~if_else(.x %in% names(post_sn_grouped),true="TRUE",false="FALSE"))) %>%
    mutate(absent2 = map2_chr(
    focal,
    associate,
    ~if_else(.y %in% post_sn_grouped[[.x]]$Association,true="TRUE",false="FALSE"))) %>%
  filter(absent1 == "TRUE") %>%
  filter(absent2 == "TRUE") %>%
  dplyr::select(-absent1,-absent2) #this removes those two new columns you made so you're just left with the ID names
#Honestly I was quite confused on parts of this, but Laura/Dr. Schmitt gave me this helpful code

post_sn_combo3<- post_sn_combo2 %>% 
  mutate(proximity = map2_int( #new column called "proximity" that is the count for when proximity code = 1 or 2
    focal, 
    associate, 
    ~post_sn_grouped %>% pluck(.x) %>% filter(Association==.y) %>% as.data.frame(.) %>% .[,2]))
post_sn_combo3

# 6. Create your matrix
post_sn_matrix<-spread(post_sn_combo3,associate,proximity) %>% column_to_rownames(var="focal") %>% data.matrix()
#post_sn_matrix
```

```{r}
post_sn_codes <- sort(post_sn_IDs)

post_sn_df <- as.data.frame(post_sn_matrix, stringsAsFactors = TRUE) #creating the matrix data frame
#post_sn_df
```

## Adding the total number of focal follows in which proximity info was collected
```{r}
post_socnet_TOTALS<- curl("https://raw.githubusercontent.com/langley1/LWTdata2016/refs/heads/main/Post-release%20Social%20Proxmity%20TOTALS.csv")
post_socnet_TOTALS<- read.csv(post_socnet_TOTALS, header = T, na.strings=c(""," ","NA")) #loading in data
head(post_socnet_TOTALS)
```

### Doing it for each individual separately 
```{r}
post_socnet_TOTALS_AM<- post_socnet_TOTALS %>%
  filter(Focal.ID == "AM") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) #adding in new column with the number of distinct focal references for that individual

post_socnet_TOTALS_ZI<- post_socnet_TOTALS %>%
  filter(Focal.ID == "ZI") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_PO<- post_socnet_TOTALS %>%
  filter(Focal.ID == "PO") %>%
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_AL<- post_socnet_TOTALS %>%
  filter(Focal.ID == "AL") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_BL<- post_socnet_TOTALS %>%
  filter(Focal.ID == "BL") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_TO<- post_socnet_TOTALS %>%
  filter(Focal.ID == "TO") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_AU<- post_socnet_TOTALS %>%
  filter(Focal.ID == "AU") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_BO<- post_socnet_TOTALS %>%
  filter(Focal.ID == "BO") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_JA<- post_socnet_TOTALS %>%
  filter(Focal.ID == "JA") %>%
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_MG<- post_socnet_TOTALS %>%
  filter(Focal.ID == "MG") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_RE<- post_socnet_TOTALS %>%
  filter(Focal.ID == "RE") %>%
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_ED<- post_socnet_TOTALS %>%
  filter(Focal.ID == "ED") %>%
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_MA<- post_socnet_TOTALS %>%
  filter(Focal.ID == "MA") %>% 
  filter(Association != c("OS","I")) %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_SK<- post_socnet_TOTALS %>%
  filter(Focal.ID == "SK") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_BM<- post_socnet_TOTALS %>%
  filter(Focal.ID == "BM") %>% 
  filter(Association != c("OS","I")) %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_NE<- post_socnet_TOTALS %>%
  filter(Focal.ID == "NE") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_KO<- post_socnet_TOTALS %>%
  filter(Focal.ID == "KO") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_TI<- post_socnet_TOTALS %>%
  filter(Focal.ID == "TI") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_CI<- post_socnet_TOTALS %>%
  filter(Focal.ID == "CI") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_HO<- post_socnet_TOTALS %>%
  filter(Focal.ID == "HO") %>% 
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 

post_socnet_TOTALS_PA<- post_socnet_TOTALS %>%
  filter(Focal.ID == "PA") %>%
  filter(Association != "OS") %>%
  mutate(total = n_distinct(FOCAL.REFERENCE)) 
```

### Making a matrix with Focial ID, Proximity Association & Total follows
```{r}
post_socnet_TOTALs_combined<- bind_rows(post_socnet_TOTALS_AL, post_socnet_TOTALS_AM, post_socnet_TOTALS_AU, post_socnet_TOTALS_BL, post_socnet_TOTALS_BM, post_socnet_TOTALS_BO, post_socnet_TOTALS_CI, post_socnet_TOTALS_ED, post_socnet_TOTALS_HO, post_socnet_TOTALS_JA, post_socnet_TOTALS_KO, post_socnet_TOTALS_MA, post_socnet_TOTALS_MG, post_socnet_TOTALS_NE, post_socnet_TOTALS_PA, post_socnet_TOTALS_PO, post_socnet_TOTALS_RE, post_socnet_TOTALS_SK, post_socnet_TOTALS_TI, post_socnet_TOTALS_TO, post_socnet_TOTALS_ZI) #combining the indiviudal dfs

post_socnet_TOTALs_clean <- post_socnet_TOTALs_combined %>%
  distinct(Focal.ID, Association, total) #have the clean out the Focal ID /Association duplicates from the table because the total focal number will be the same throughout so we don't need the duplicates

post_socnet_TOTALs_matrix <- post_socnet_TOTALs_clean %>% #making it into a pairwise table
  pivot_wider(
    names_from = Association,
    values_from = total,
    values_fill = 0    # fill missing with 0 instead of NA
  )

post_socnet_TOTALs_matrix <- post_socnet_TOTALs_matrix %>% 
  column_to_rownames('Focal.ID') #changing Focal ID column into row names

post_socnet_TOTALs_matrix <- post_socnet_TOTALs_matrix %>%
  select(AL,AM,AU,BL,BM,BO,CI,ED,HO,JA,KO,MA,MG,NE,PA,PO,RE,SK,TI,TO,ZI) # Specify the new order of column name

post_socnet_TOTALs_matrix<- as.matrix(post_socnet_TOTALs_matrix) #turning it into a matrix, has to come after all the other adjustments to the df
```

## Trying to account for SURVIVAL OVERLAP across indiviudals in order to make accurate social proximity scores
```{r}
#Now I have to do the matrix math but I need to tell it that if there's an NA in the post_sn_matrix, then it should give an NA in the final matrix 

#creating a daily_effort df: columns with focal ID, date, and n_follows for each focal reference number
post_socnet_TOTALs_combined_withdate<- post_socnet_TOTALs_combined %>%
  mutate(date = as.Date(paste(Year, Month, Day, sep = "-"))) %>% #
  group_by(Focal.ID, date) %>%
  summarise(
    n_follows = n_distinct(FOCAL.REFERENCE),
    .groups = "drop"
  )

#checking to see the total number of focal follows per individual 
post_socnet_TOTALs_combined_withdate %>%
  group_by(Focal.ID) %>%
  summarise(total_follows = sum(n_follows))

# df_alive: ID, start_date, end_date
post_socnet_TOTALs_alive<- post_socnet_TOTALs_combined_withdate %>%
  group_by(Focal.ID) %>%
  summarise(
    start_date = as.Date("2016-3-18"),
    end_date   = max(date),
    .groups = "drop"
  )

post_socnet_TOTALs_alive <- post_socnet_TOTALs_alive %>% #manually editing the end date for the indiviudals based on whether they survived or died (got this date from supp material table)
  mutate(
    end_date = case_when(
      Focal.ID %in% c("PO","BL","AM","ED","KO","MA","MY","CI","HO") ~ as.Date("2016-12-15"),  
      Focal.ID == "AL" ~ as.Date("2016-11-18"),
      Focal.ID == "TO" ~ as.Date("2016-08-23"),
      Focal.ID == "ZI" ~ as.Date("2016-03-22"),
      Focal.ID == "AU" ~ as.Date("2016-12-08"),
      Focal.ID == "BO" ~ as.Date("2016-10-08"),
      Focal.ID == "JA" ~ as.Date("2016-06-11"),
      Focal.ID == "MG" ~ as.Date("2016-08-23"),
      Focal.ID == "RE" ~ as.Date("2016-10-14"),
      Focal.ID == "SK" ~ as.Date("2016-11-23"),
      Focal.ID == "BM" ~ as.Date("2016-09-30"),
      Focal.ID == "NE" ~ as.Date("2016-08-13"),
      Focal.ID == "TI" ~ as.Date("2016-08-30"),
      Focal.ID == "PA" ~ as.Date("2016-10-25"),
    )
  )

#1. create pairwise table (focal, associate)
ids <- post_socnet_TOTALs_alive$Focal.ID
pairs <- expand.grid(focal = ids, associate = ids, stringsAsFactors = FALSE) %>% as_tibble()

#2. join associate alive-range to daily effort rows and filter dates when associate is alive
# First ensure daily effort df has Focal.ID and date
denom_by_pair <- post_socnet_TOTALs_combined_withdate %>%
  rename(focal = Focal.ID) %>%
  # join pairs to allow filtering by each associate's alive range:
  left_join(pairs, by = "focal") %>%          # now each row repeats for each associate
  left_join(post_socnet_TOTALs_alive %>% rename(associate = Focal.ID,
                               assoc_start = start_date,
                               assoc_end = end_date),
            by = "associate") %>%
  filter(date >= assoc_start & date <= assoc_end) %>%
  group_by(focal, associate) %>%
  summarise(total_focal_follows_when_assoc_alive = sum(n_follows, na.rm = TRUE), .groups = "drop")

#3. turn into matrix aligned to our proximity matrix (post_sn_matrix)
denom_mat2 <- denom_by_pair %>%
  pivot_wider(names_from = associate, values_from = total_focal_follows_when_assoc_alive, values_fill = 0) %>%
  column_to_rownames("focal") %>%
  as.matrix()

#Now dividing the proximity matrix by our "days alive overlap" matrix
proximity_rate_matrix <- post_sn_matrix / denom_mat2
proximity_rate_matrix[denom_mat2 == 0] <- NA
```

The rate (or probability) that associate individual was seen in close proximity during a focal follow of X individual, conditional on both being alive at the same time (the wild immigrant males are still part of both of these matrices but I don't think we'll get eigenvector scores for them).

# Calculating Post-Release Eigenvector Centrality Scores (using proximity rate data)
## Directed Data
```{r}
proximity_rate_clean <- proximity_rate_matrix
proximity_rate_clean[is.na(proximity_rate_clean)] <- 0 #turning NAs into 0s

# Build a graph from the adjacency matrix
proximity_rate_graph <- graph_from_adjacency_matrix(
  proximity_rate_clean,
  mode = "directed",   # or "undirected", depending on your network
  weighted = TRUE,
  diag = FALSE
)

#calculating post-release eigenvector centrality with DIRECTED relationships (focal -> associate)
post_eigen_centrality <- eigen_centrality(proximity_rate_graph, directed = TRUE, weights = E(proximity_rate_graph)$weight)

#extracting the scores
post_eigen_centrality_scores <- post_eigen_centrality$vector
post_eigen_centrality_scores

#putting eigenvector scores back into a df
post_eigen_centrality_df <- data.frame(
  Focal.ID = names(post_eigen_centrality_scores),
  eigenvector_centrality = post_eigen_centrality_scores
)
post_eigen_centrality_df
```

## Eigenvector centrality using undirected data
```{r}
proximity_rate_undirect <- (proximity_rate_clean + t(proximity_rate_clean)) / 2 
#t() takes the transpose of the matrix so the roles of focal and associate are swapped
#we add the original matrix and the transposed matrix together 
#divide by 2 to get the average of the two directional values to reflect the mutual association strength between individuals, rather than two directional rates

proximity_rate_graph_undirect <- graph_from_adjacency_matrix(
  proximity_rate_undirect, mode = "undirected", weighted = TRUE, diag = FALSE)

#calculating post-release eigenvector centrality with UNDIRECTED relationships (doesn't matter who is focal and who is associate)
post_eigen_centrality_undirect <- eigen_centrality(proximity_rate_graph_undirect, directed = FALSE, weights = E(proximity_rate_graph_undirect)$weight)

#extracting the scores
post_eigen_centrality_scores_undirect <- post_eigen_centrality_undirect$vector
post_eigen_centrality_scores_undirect

#putting eigenvector scores back into a df
post_eigen_centrality_df_undirect <- data.frame(
  Focal.ID = names(post_eigen_centrality_scores_undirect),
  eigenvector_centrality = post_eigen_centrality_scores_undirect
)
post_eigen_centrality_df_undirect
```

The edge in this undirected case means "relationship" rather than "interaction direction" because we want a pairwise association strength, not a directional interaction. 